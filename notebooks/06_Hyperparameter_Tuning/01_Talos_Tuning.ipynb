{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Talos hyperparamater tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if not COLAB:\n",
    "    ROOT = os.path.join(os.getcwd(), '..', '..') \n",
    "\n",
    "    src_dir = os.path.join(ROOT, 'src')\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "    from constants import *\n",
    "else:\n",
    "    N_MELS = 80\n",
    "    CONTEXT_WINDOW = 17\n",
    "    SUB_DIVISION = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TensorFlow modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and load required dependencies"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install talos\n",
    "!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('COLAB_TPU_ADDR' in os.environ.keys()):\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "    tf.config.experimental_connect_to_host(resolver.master())\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Sub_Divisions</th>\n",
       "      <th>Binary_Labels</th>\n",
       "      <th>Weighted_Labels</th>\n",
       "      <th>Weights</th>\n",
       "      <th>IDS</th>\n",
       "      <th>Beat_times</th>\n",
       "      <th>Labels</th>\n",
       "      <th>BPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_12step</td>\n",
       "      <td>[[[[-1.09821814 -1.1065893  -1.10661448 -1.106...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 2.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0001_12step, 0001_12step, 0001_12step, 0001_1...</td>\n",
       "      <td>[0.0, 0.5309729999999999, 1.0619459999999998, ...</td>\n",
       "      <td>[0.0, 8.495567999999999, 25.486704, 42.4753280...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003_6foot7foot</td>\n",
       "      <td>[[[[-1.53216075 -1.5321569  -1.53216468 -1.532...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[1.0, 2.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, ...</td>\n",
       "      <td>[0003_6foot7foot, 0003_6foot7foot, 0003_6foot7...</td>\n",
       "      <td>[2.857108, 3.571394, 4.28568, 4.99996600000000...</td>\n",
       "      <td>[2.857108, 8.571396, 31.428548, 37.14283599999...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004_abc</td>\n",
       "      <td>[[[[-1.28460321 -1.29111018 -1.29454499 -1.302...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 2.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0004_abc, 0004_abc, 0004_abc, 0004_abc, 0004_...</td>\n",
       "      <td>[2.666656, 3.238084, 3.952369, 4.597529, 5.242...</td>\n",
       "      <td>[2.666656, 28.300542999999998, 58.263180000000...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006_aint2proud2beg</td>\n",
       "      <td>[[[[-1.47435298 -1.48497827 -1.49480312 -1.497...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 2.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0006_aint2proud2beg, 0006_aint2proud2beg, 000...</td>\n",
       "      <td>[0.0, 0.572203, 1.144406, 1.716609, 2.288812, ...</td>\n",
       "      <td>[0.0, 27.4652, 45.203726, 63.518522999999995, ...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008_america</td>\n",
       "      <td>[[[[-1.25359642 -1.25824786 -1.26322129 -1.265...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 2.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0008_america, 0008_america, 0008_america, 000...</td>\n",
       "      <td>[3.871208, 4.359011, 4.846814, 5.338616, 5.830...</td>\n",
       "      <td>[3.871208, 10.56504, 33.217138, 56.85190400000...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  File                                      Sub_Divisions  \\\n",
       "0          0001_12step  [[[[-1.09821814 -1.1065893  -1.10661448 -1.106...   \n",
       "1      0003_6foot7foot  [[[[-1.53216075 -1.5321569  -1.53216468 -1.532...   \n",
       "2             0004_abc  [[[[-1.28460321 -1.29111018 -1.29454499 -1.302...   \n",
       "3  0006_aint2proud2beg  [[[[-1.47435298 -1.48497827 -1.49480312 -1.497...   \n",
       "4         0008_america  [[[[-1.25359642 -1.25824786 -1.26322129 -1.265...   \n",
       "\n",
       "                                       Binary_Labels  \\\n",
       "0  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     Weighted_Labels  \\\n",
       "0  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "2  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                             Weights  \\\n",
       "0  [1.0, 2.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [1.0, 2.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, ...   \n",
       "2  [1.0, 2.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 2.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [1.0, 2.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                                 IDS  \\\n",
       "0  [0001_12step, 0001_12step, 0001_12step, 0001_1...   \n",
       "1  [0003_6foot7foot, 0003_6foot7foot, 0003_6foot7...   \n",
       "2  [0004_abc, 0004_abc, 0004_abc, 0004_abc, 0004_...   \n",
       "3  [0006_aint2proud2beg, 0006_aint2proud2beg, 000...   \n",
       "4  [0008_america, 0008_america, 0008_america, 000...   \n",
       "\n",
       "                                          Beat_times  \\\n",
       "0  [0.0, 0.5309729999999999, 1.0619459999999998, ...   \n",
       "1  [2.857108, 3.571394, 4.28568, 4.99996600000000...   \n",
       "2  [2.666656, 3.238084, 3.952369, 4.597529, 5.242...   \n",
       "3  [0.0, 0.572203, 1.144406, 1.716609, 2.288812, ...   \n",
       "4  [3.871208, 4.359011, 4.846814, 5.338616, 5.830...   \n",
       "\n",
       "                                              Labels  BPM  \n",
       "0  [0.0, 8.495567999999999, 25.486704, 42.4753280...  113  \n",
       "1  [2.857108, 8.571396, 31.428548, 37.14283599999...   84  \n",
       "2  [2.666656, 28.300542999999998, 58.263180000000...   94  \n",
       "3  [0.0, 27.4652, 45.203726, 63.518522999999995, ...  105  \n",
       "4  [3.871208, 10.56504, 33.217138, 56.85190400000...  136  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(ROOT, SUB_DIVS_DIR, 'beats', 'harmonix.p') if not COLAB else '/content/drive/MyDrive/fyp/collabs/harmonix.p'\n",
    "harmonix_beats = pickle.load(open(path, 'rb'))\n",
    "harmonix_beats = harmonix_beats.head(50)\n",
    "harmonix_beats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = harmonix_beats\n",
    "y = harmonix_beats['Binary_Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, _, _ = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, _, _ = train_test_split(X_train, X_train['Binary_Labels'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate(X_train['Weighted_Labels'].values)\n",
    "y_test = np.concatenate(X_test['Binary_Labels'].values)\n",
    "y_val = np.concatenate(X_val['Binary_Labels'].values)\n",
    "\n",
    "ids_train = np.concatenate(X_train['IDS'].values)\n",
    "ids_test = np.concatenate(X_test['IDS'].values)\n",
    "ids_val = np.concatenate(X_val['IDS'].values)\n",
    "\n",
    "w_train = np.concatenate(X_train['Weights'].values)\n",
    "w_test = np.concatenate(X_test['Weights'].values)\n",
    "w_val = np.concatenate(X_val['Weights'].values)\n",
    "\n",
    "X_train = np.concatenate(X_train['Sub_Divisions'].values)\n",
    "X_test = np.concatenate(X_test['Sub_Divisions'].values)\n",
    "X_val = np.concatenate(X_val['Sub_Divisions'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.swapaxes(2,3)\n",
    "X_test = X_test.swapaxes(2,3)\n",
    "X_val = X_val.swapaxes(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the grid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'first_neuron': [8, 16, 32],\n",
    "    'second_neuron': [16, 32, 64],\n",
    "    'third_neuron': [64, 128, 256],\n",
    "    'dropout_one': [0.3, 0.4, 0.5],\n",
    "    'dropout_two': [0.3, 0.4, 0.5],\n",
    "    'dropout_three': [0.2, 0.3, 0.4, 0.5],\n",
    "    'activation':['elu', 'relu'],\n",
    "    'optimizer': ['Adam', 'SGD'],\n",
    "    'batch_size': [24, 32],\n",
    "    'learning_rate': (0.1, 10, 10),\n",
    "    'epochs': [80, 100],\n",
    "    'w_train': [w_train]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics loader helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metrics():\n",
    "    return [\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.15),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(params):\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "    return Sequential([\n",
    "        Input(input_shape=(N_MELS, CONTEXT_WINDOW, SUBDIVISIONS)),\n",
    "        Conv2D(params['first_neuron'], (8,6), activation=params['activation'], kernel_initializer=initializer, padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(5, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(params['dropout_one']),\n",
    "        Conv2D(params['second_neuron'], (6,4), activation=params['activation'], padding=\"same\", kernel_initializer=initializer),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(params['dropout_one']),\n",
    "        Flatten(),\n",
    "        Dense(params['third_neuron'], activation=params['activation']),\n",
    "        Dropout(params['dropout_two']),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X_train, y_train, X_val, y_val, params):\n",
    "    return model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        batch_size=params['batch_size'],\n",
    "        epochs=params['epochs'], \n",
    "        shuffle=True,\n",
    "        verbose=0,\n",
    "        sample_weight=params['w_train'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tuning(X_train, y_train, X_val, y_val, params):\n",
    "    load_metrics()\n",
    "    model = build_model()\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=METRICS)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=20, mode='max', restore_best_weights=True)\n",
    "    history = fit_model() \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only run in colab\n",
    "if ('COLAB_TPU_ADDR' in os.environ.keys()):\n",
    "    with strategy.scope():\n",
    "        scan_object = talos.Scan(\n",
    "            X_train,\n",
    "            y_train, \n",
    "            params=params,\n",
    "            model=model_tuning,\n",
    "            experiment_name='nnssa',\n",
    "            fraction_limit=.001,\n",
    "            x_val = X_val,\n",
    "            y_val = y_val\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
