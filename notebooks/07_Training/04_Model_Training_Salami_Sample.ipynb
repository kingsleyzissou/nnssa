{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT = '/content/drive/MyDrive/fyp/collabs/'\n",
    "else:\n",
    "    ROOT = os.path.join(os.getcwd(), '..', '..') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Colab libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    !pip install pickle5\n",
    "    import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load custom modules"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install git+https://github.com/kingsleyzissou/nnssa.git@0.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnssa.constants import *\n",
    "from nnssa.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TensorFlow modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics():\n",
    "    return [\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.15),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('COLAB_TPU_ADDR' in os.environ.keys()):\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "    tf.config.experimental_connect_to_host(resolver.master())\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress bars!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Sub_Divisions</th>\n",
       "      <th>Binary_Labels</th>\n",
       "      <th>Weighted_Labels</th>\n",
       "      <th>Weights</th>\n",
       "      <th>IDS</th>\n",
       "      <th>Beat_times</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>956</td>\n",
       "      <td>/Users/admin/Downloads/fypdataset/notebooks/05...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, ...</td>\n",
       "      <td>[956, 956, 956, 956, 956, 956, 956, 956, 956, ...</td>\n",
       "      <td>[0.0, 2.5541950113378684, 3.9009523809523814, ...</td>\n",
       "      <td>[28.746303854, 49.357959183, 91.03056689299999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>958</td>\n",
       "      <td>/Users/admin/Downloads/fypdataset/notebooks/05...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, ...</td>\n",
       "      <td>[958, 958, 958, 958, 958, 958, 958, 958, 958, ...</td>\n",
       "      <td>[0.0, 0.18575963718820865, 0.8823582766439909,...</td>\n",
       "      <td>[0.045, 26.129208333, 71.4750625, 116.7300625,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>960</td>\n",
       "      <td>/Users/admin/Downloads/fypdataset/notebooks/05...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[960, 960, 960, 960, 960, 960, 960, 960, 960, ...</td>\n",
       "      <td>[0.0, 0.18575963718820865, 1.3931972789115643,...</td>\n",
       "      <td>[0.048979590999999996, 76.260068027, 108.70204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>962</td>\n",
       "      <td>/Users/admin/Downloads/fypdataset/notebooks/05...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 3.0, 0.5, 1.0, ...</td>\n",
       "      <td>[962, 962, 962, 962, 962, 962, 962, 962, 962, ...</td>\n",
       "      <td>[0.0, 0.3715192743764173, 1.0216780045351477, ...</td>\n",
       "      <td>[15.18585034, 56.47031746, 104.25839002200001,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>968</td>\n",
       "      <td>/Users/admin/Downloads/fypdataset/notebooks/05...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, ...</td>\n",
       "      <td>[3.0, 3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 0.5, ...</td>\n",
       "      <td>[968, 968, 968, 968, 968, 968, 968, 968, 968, ...</td>\n",
       "      <td>[0.0, 0.4643990929705216, 1.7182766439909296, ...</td>\n",
       "      <td>[0.865306122, 6.802834467, 27.484149659, 47.89...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   File                                      Sub_Divisions  \\\n",
       "0   956  /Users/admin/Downloads/fypdataset/notebooks/05...   \n",
       "1   958  /Users/admin/Downloads/fypdataset/notebooks/05...   \n",
       "2   960  /Users/admin/Downloads/fypdataset/notebooks/05...   \n",
       "3   962  /Users/admin/Downloads/fypdataset/notebooks/05...   \n",
       "6   968  /Users/admin/Downloads/fypdataset/notebooks/05...   \n",
       "\n",
       "                                       Binary_Labels  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "6  [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     Weighted_Labels  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, ...   \n",
       "2  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, ...   \n",
       "6  [1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, ...   \n",
       "\n",
       "                                             Weights  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, ...   \n",
       "1  [3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, ...   \n",
       "2  [3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 3.0, 0.5, 1.0, ...   \n",
       "6  [3.0, 3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 0.5, ...   \n",
       "\n",
       "                                                 IDS  \\\n",
       "0  [956, 956, 956, 956, 956, 956, 956, 956, 956, ...   \n",
       "1  [958, 958, 958, 958, 958, 958, 958, 958, 958, ...   \n",
       "2  [960, 960, 960, 960, 960, 960, 960, 960, 960, ...   \n",
       "3  [962, 962, 962, 962, 962, 962, 962, 962, 962, ...   \n",
       "6  [968, 968, 968, 968, 968, 968, 968, 968, 968, ...   \n",
       "\n",
       "                                          Beat_times  \\\n",
       "0  [0.0, 2.5541950113378684, 3.9009523809523814, ...   \n",
       "1  [0.0, 0.18575963718820865, 0.8823582766439909,...   \n",
       "2  [0.0, 0.18575963718820865, 1.3931972789115643,...   \n",
       "3  [0.0, 0.3715192743764173, 1.0216780045351477, ...   \n",
       "6  [0.0, 0.4643990929705216, 1.7182766439909296, ...   \n",
       "\n",
       "                                              Labels  \n",
       "0  [28.746303854, 49.357959183, 91.03056689299999...  \n",
       "1  [0.045, 26.129208333, 71.4750625, 116.7300625,...  \n",
       "2  [0.048979590999999996, 76.260068027, 108.70204...  \n",
       "3  [15.18585034, 56.47031746, 104.25839002200001,...  \n",
       "6  [0.865306122, 6.802834467, 27.484149659, 47.89...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if COLAB:\n",
    "    salami_beats = pickle.load(open(os.path.join(ROOT, SUB_DIVS_DIR, 'bars', 'salami.p'), 'rb'))\n",
    "else:\n",
    "    salami_beats = pd.read_pickle(os.path.join(ROOT, SUB_DIVS_DIR, 'bars', 'salami.p'))\n",
    "salami_beats = salami_beats.head(100)\n",
    "salami_beats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Mel Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_np(file):\n",
    "    return np.load(os.path.join(ROOT, SUB_DIVS_DIR, file), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 285.66it/s]\n"
     ]
    }
   ],
   "source": [
    "salami_beats['Sub_Divisions'] = salami_beats['Sub_Divisions'].progress_map(load_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = salami_beats.head(50).copy()\n",
    "y = salami_beats.head(50)['Binary_Labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, _, _ = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, _, _ = train_test_split(X_train, X_train['Binary_Labels'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.concatenate(X_train['Over_Labels'].values)\n",
    "y_train = np.concatenate(X_train['Binary_Labels'].values)\n",
    "y_test = np.concatenate(X_test['Binary_Labels'].values)\n",
    "y_val = np.concatenate(X_val['Binary_Labels'].values)\n",
    "\n",
    "ids_test = np.concatenate(X_test['IDS'].values)\n",
    "\n",
    "# w_train = np.concatenate(X_train['Over_Weights'].values)\n",
    "w_train = np.concatenate(X_train['Weights'].values)\n",
    "w_test = np.concatenate(X_test['Weights'].values)\n",
    "w_val = np.concatenate(X_val['Weights'].values)\n",
    "\n",
    "# X_train = np.concatenate(X_train['Oversamples'].values)\n",
    "X_train = np.concatenate(X_train['Sub_Divisions'].values)\n",
    "X_test = np.concatenate(X_test['Sub_Divisions'].values)\n",
    "X_val = np.concatenate(X_val['Sub_Divisions'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 321, 0.0: 2307})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Initial Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial bias: [-1.97226214]\n"
     ]
    }
   ],
   "source": [
    "count = np.bincount(y_train.astype('int64'))\n",
    "neg, pos = count[0], count[1]\n",
    "total = neg + pos\n",
    "initial_bias = np.log([pos/neg])\n",
    "print(f'Initial bias: {initial_bias}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(initial_bias):\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "    bias_initializer = tf.keras.initializers.Constant(initial_bias)\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "    return Sequential([\n",
    "        Input(shape=(N_MELS, 4, 33)),\n",
    "        Conv2D(8, 8, activation='relu', kernel_initializer=initializer, padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(5, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Conv2D(16, 6, activation='relu', padding=\"same\", kernel_initializer=initializer),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='sigmoid'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid', bias_initializer=bias_initializer)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3933\n",
      "Epoch 1/80\n",
      "21/21 [==============================] - 3s 101ms/step - loss: 0.7697 - accuracy: 0.2371 - precision: 0.1543 - recall: 0.1807 - auc: 0.5301 - val_loss: 0.3851 - val_accuracy: 0.3644 - val_precision: 0.3333 - val_recall: 0.0575 - val_auc: 0.5702\n",
      "Epoch 2/80\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 0.7218 - accuracy: 0.2097 - precision: 0.1703 - recall: 0.1215 - auc: 0.5712 - val_loss: 0.5782 - val_accuracy: 0.1331 - val_precision: 0.1892 - val_recall: 0.3218 - val_auc: 0.6311\n",
      "Epoch 3/80\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 0.7131 - accuracy: 0.2013 - precision: 0.2029 - recall: 0.1745 - auc: 0.5811 - val_loss: 0.4071 - val_accuracy: 0.2886 - val_precision: 0.2105 - val_recall: 0.0920 - val_auc: 0.6450\n",
      "Epoch 4/80\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 0.7009 - accuracy: 0.2519 - precision: 0.2308 - recall: 0.2336 - auc: 0.6051 - val_loss: 0.3546 - val_accuracy: 0.4502 - val_precision: 0.2941 - val_recall: 0.0575 - val_auc: 0.6690\n",
      "Epoch 5/80\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 0.6971 - accuracy: 0.2679 - precision: 0.2022 - recall: 0.2274 - auc: 0.6169 - val_loss: 0.3410 - val_accuracy: 0.5808 - val_precision: 0.2941 - val_recall: 0.0575 - val_auc: 0.6674\n",
      "Epoch 6/80\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 0.6904 - accuracy: 0.2858 - precision: 0.2060 - recall: 0.2150 - auc: 0.6447 - val_loss: 0.3856 - val_accuracy: 0.3532 - val_precision: 0.2500 - val_recall: 0.0690 - val_auc: 0.6591\n",
      "Epoch 7/80\n",
      "21/21 [==============================] - 2s 92ms/step - loss: 0.6837 - accuracy: 0.3333 - precision: 0.2350 - recall: 0.3053 - auc: 0.6621 - val_loss: 0.3777 - val_accuracy: 0.3632 - val_precision: 0.2800 - val_recall: 0.0805 - val_auc: 0.6631\n",
      "Epoch 8/80\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 0.6586 - accuracy: 0.3421 - precision: 0.2793 - recall: 0.3271 - auc: 0.6905 - val_loss: 0.4562 - val_accuracy: 0.2102 - val_precision: 0.2941 - val_recall: 0.2299 - val_auc: 0.6589\n",
      "Epoch 9/80\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 0.6498 - accuracy: 0.3193 - precision: 0.2665 - recall: 0.3396 - auc: 0.6969 - val_loss: 0.4185 - val_accuracy: 0.3184 - val_precision: 0.2353 - val_recall: 0.1379 - val_auc: 0.6702\n",
      "Epoch 10/80\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 0.6478 - accuracy: 0.3436 - precision: 0.2953 - recall: 0.3302 - auc: 0.6995 - val_loss: 0.4264 - val_accuracy: 0.3420 - val_precision: 0.2295 - val_recall: 0.1609 - val_auc: 0.6461\n",
      "Epoch 11/80\n",
      "21/21 [==============================] - 2s 92ms/step - loss: 0.6381 - accuracy: 0.3858 - precision: 0.2874 - recall: 0.3769 - auc: 0.7171 - val_loss: 0.3830 - val_accuracy: 0.3993 - val_precision: 0.2683 - val_recall: 0.1264 - val_auc: 0.6828\n",
      "Epoch 12/80\n",
      "21/21 [==============================] - 2s 92ms/step - loss: 0.6258 - accuracy: 0.4136 - precision: 0.3032 - recall: 0.3551 - auc: 0.7285 - val_loss: 0.5304 - val_accuracy: 0.2040 - val_precision: 0.2125 - val_recall: 0.3908 - val_auc: 0.6786\n",
      "Epoch 13/80\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 0.6460 - accuracy: 0.4030 - precision: 0.2668 - recall: 0.3832 - auc: 0.7148 - val_loss: 0.4119 - val_accuracy: 0.2861 - val_precision: 0.2500 - val_recall: 0.1494 - val_auc: 0.6798\n",
      "Epoch 14/80\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 0.6249 - accuracy: 0.4098 - precision: 0.3289 - recall: 0.3832 - auc: 0.7308 - val_loss: 0.4888 - val_accuracy: 0.2637 - val_precision: 0.2114 - val_recall: 0.2989 - val_auc: 0.6892\n",
      "Epoch 15/80\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 0.6168 - accuracy: 0.4110 - precision: 0.3045 - recall: 0.4611 - auc: 0.7468 - val_loss: 0.3621 - val_accuracy: 0.5498 - val_precision: 0.3333 - val_recall: 0.1609 - val_auc: 0.7035\n",
      "Epoch 16/80\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 0.5816 - accuracy: 0.4418 - precision: 0.3641 - recall: 0.4798 - auc: 0.7720 - val_loss: 0.3980 - val_accuracy: 0.4080 - val_precision: 0.2239 - val_recall: 0.1724 - val_auc: 0.7022\n",
      "Epoch 17/80\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 0.6070 - accuracy: 0.4269 - precision: 0.3289 - recall: 0.4673 - auc: 0.7560 - val_loss: 0.3664 - val_accuracy: 0.5336 - val_precision: 0.2941 - val_recall: 0.1149 - val_auc: 0.6536\n",
      "Epoch 18/80\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 0.6036 - accuracy: 0.4144 - precision: 0.3430 - recall: 0.4050 - auc: 0.7550 - val_loss: 0.3858 - val_accuracy: 0.5274 - val_precision: 0.2895 - val_recall: 0.1264 - val_auc: 0.6386\n",
      "Epoch 19/80\n",
      "21/21 [==============================] - 2s 92ms/step - loss: 0.5817 - accuracy: 0.5354 - precision: 0.3731 - recall: 0.4673 - auc: 0.7850 - val_loss: 0.5264 - val_accuracy: 0.3085 - val_precision: 0.1990 - val_recall: 0.4483 - val_auc: 0.6629\n",
      "Epoch 20/80\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 0.5765 - accuracy: 0.4928 - precision: 0.3411 - recall: 0.5016 - auc: 0.7827 - val_loss: 0.4742 - val_accuracy: 0.4391 - val_precision: 0.1849 - val_recall: 0.3103 - val_auc: 0.6438\n",
      "Epoch 21/80\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 0.5569 - accuracy: 0.4768 - precision: 0.3767 - recall: 0.5140 - auc: 0.7985 - val_loss: 0.4390 - val_accuracy: 0.4117 - val_precision: 0.1753 - val_recall: 0.1954 - val_auc: 0.6518\n",
      "Epoch 22/80\n",
      "21/21 [==============================] - 2s 92ms/step - loss: 0.5750 - accuracy: 0.5240 - precision: 0.3298 - recall: 0.4798 - auc: 0.7937 - val_loss: 0.4767 - val_accuracy: 0.3383 - val_precision: 0.2000 - val_recall: 0.3103 - val_auc: 0.6719\n",
      "Epoch 23/80\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 0.5605 - accuracy: 0.5205 - precision: 0.3819 - recall: 0.5389 - auc: 0.8064 - val_loss: 0.4335 - val_accuracy: 0.4092 - val_precision: 0.2627 - val_recall: 0.3563 - val_auc: 0.6963\n",
      "Epoch 24/80\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 0.5723 - accuracy: 0.5008 - precision: 0.3576 - recall: 0.5202 - auc: 0.7909 - val_loss: 0.3737 - val_accuracy: 0.5808 - val_precision: 0.2553 - val_recall: 0.1379 - val_auc: 0.6763\n",
      "Epoch 25/80\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 0.5318 - accuracy: 0.5415 - precision: 0.4196 - recall: 0.5607 - auc: 0.8217 - val_loss: 0.4503 - val_accuracy: 0.4652 - val_precision: 0.2165 - val_recall: 0.2414 - val_auc: 0.6566\n",
      "Epoch 26/80\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 0.5625 - accuracy: 0.5266 - precision: 0.3560 - recall: 0.5701 - auc: 0.8011 - val_loss: 0.3740 - val_accuracy: 0.5808 - val_precision: 0.2381 - val_recall: 0.1149 - val_auc: 0.6555\n",
      "Epoch 27/80\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 0.5431 - accuracy: 0.5677 - precision: 0.3892 - recall: 0.5639 - auc: 0.8166 - val_loss: 0.4639 - val_accuracy: 0.3794 - val_precision: 0.1846 - val_recall: 0.2759 - val_auc: 0.6585\n",
      "Epoch 28/80\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 0.5217 - accuracy: 0.5643 - precision: 0.3872 - recall: 0.5296 - auc: 0.8305 - val_loss: 0.5670 - val_accuracy: 0.3719 - val_precision: 0.1855 - val_recall: 0.5287 - val_auc: 0.6641\n",
      "Epoch 29/80\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 0.5307 - accuracy: 0.5487 - precision: 0.3820 - recall: 0.5701 - auc: 0.8223 - val_loss: 0.4192 - val_accuracy: 0.4863 - val_precision: 0.2857 - val_recall: 0.2759 - val_auc: 0.6765\n",
      "Epoch 30/80\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 0.5198 - accuracy: 0.5887 - precision: 0.4308 - recall: 0.6012 - auc: 0.8358 - val_loss: 0.5111 - val_accuracy: 0.3731 - val_precision: 0.2012 - val_recall: 0.3908 - val_auc: 0.6612\n",
      "Epoch 31/80\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 0.5431 - accuracy: 0.5765 - precision: 0.3755 - recall: 0.5452 - auc: 0.8217 - val_loss: 0.3507 - val_accuracy: 0.6629 - val_precision: 0.3636 - val_recall: 0.1839 - val_auc: 0.6964\n",
      "Epoch 32/80\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 0.4984 - accuracy: 0.5997 - precision: 0.4074 - recall: 0.5826 - auc: 0.8455 - val_loss: 0.4173 - val_accuracy: 0.5323 - val_precision: 0.2340 - val_recall: 0.2529 - val_auc: 0.6888\n",
      "Epoch 33/80\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 0.5186 - accuracy: 0.5906 - precision: 0.3894 - recall: 0.6199 - auc: 0.8384 - val_loss: 0.3967 - val_accuracy: 0.5622 - val_precision: 0.2500 - val_recall: 0.2184 - val_auc: 0.7027\n",
      "Epoch 34/80\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 0.4921 - accuracy: 0.5776 - precision: 0.4053 - recall: 0.6137 - auc: 0.8520 - val_loss: 0.4207 - val_accuracy: 0.5597 - val_precision: 0.2233 - val_recall: 0.2644 - val_auc: 0.6843\n",
      "Epoch 35/80\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 0.4969 - accuracy: 0.6088 - precision: 0.4204 - recall: 0.6417 - auc: 0.8529 - val_loss: 0.4732 - val_accuracy: 0.4975 - val_precision: 0.2246 - val_recall: 0.3563 - val_auc: 0.6891\n"
     ]
    }
   ],
   "source": [
    "model = build_model(initial_bias)\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.05, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=get_metrics())\n",
    "\n",
    "results = model.evaluate(X_test, y_test, batch_size=32, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=20, mode='max', restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size=128,\n",
    "    epochs=80, \n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    sample_weight=w_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 1s 623us/step\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.4759 - precision: 0.3173 - recall: 0.2750 - auc: 0.7068\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, batch_size=1, verbose=1)\n",
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.91      0.90       792\n",
      "         1.0       0.32      0.28      0.29       120\n",
      "\n",
      "    accuracy                           0.83       912\n",
      "   macro avg       0.60      0.59      0.60       912\n",
      "weighted avg       0.82      0.83      0.82       912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [1 if (p > 0.5) else 0 for p in preds]\n",
    "y_pred = np.asarray(y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score:  0.26178511249133835\n",
      "Precision:  0.2889189976689977\n",
      "Recall:  0.25780856824335086\n"
     ]
    }
   ],
   "source": [
    "f_score, precision, recall = evaluate(salami_beats, preds, ids_test, True)\n",
    "\n",
    "print(\"F-score: \", f_score)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best score\n",
    " * Every iteration of this notebook has a different result\n",
    " * The best score achieved is reported below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "3 seconds:\n",
    "F-score:  0.7079411816253922\n",
    "Precision:  0.7491938013677144\n",
    "Recall:  0.7204761904761905\n",
    "\n",
    "0.5 seconds:\n",
    "F-score:  0.3044451156585869\n",
    "Precision:  0.2801110180142438\n",
    "Recall:  0.35031746031746025\n",
    "\n",
    "2 bars:\n",
    "F-score:  0.7391024180497865\n",
    "Precision:  0.7825271347010477\n",
    "Recall:  0.7499206349206349\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best score architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model = Sequential([\n",
    "    Input(shape=(N_MELS, 4, 33)),\n",
    "    Conv2D(8, 8, activation='relu', kernel_initializer=initializer, padding=\"same\"),\n",
    "    MaxPooling2D(pool_size=(5, 2)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(16, 6, activation='relu', padding=\"same\", kernel_initializer=initializer),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='sigmoid'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid', bias_initializer=bias_initializer)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.save(os.path.join(ROOT, 'models', 'binary_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.savez(os.path.join(ROOT, 'data', '06_Results', 'salami.npz'), preds=preds, ids=ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
