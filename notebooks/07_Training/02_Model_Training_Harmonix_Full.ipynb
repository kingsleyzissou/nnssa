{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT = '/content/drive/MyDrive/fyp/collabs/'\n",
    "else:\n",
    "    ROOT = os.path.join(os.getcwd(), '..', '..') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Colab libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    !pip install pickle5\n",
    "    import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load custom modules"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install git+https://github.com/kingsleyzissou/nnssa.git@0.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnssa.constants import *\n",
    "from nnssa.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TensorFlow modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics():\n",
    "    return [\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.15),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('COLAB_TPU_ADDR' in os.environ.keys()):\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "    tf.config.experimental_connect_to_host(resolver.master())\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress bars!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Sub_Divisions</th>\n",
       "      <th>Binary_Labels</th>\n",
       "      <th>Weighted_Labels</th>\n",
       "      <th>Weights</th>\n",
       "      <th>IDS</th>\n",
       "      <th>Beat_times</th>\n",
       "      <th>Labels</th>\n",
       "      <th>BPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_12step</td>\n",
       "      <td>bars/harmonix/0001_12step.npy</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0001_12step, 0001_12step, 0001_12step, 0001_1...</td>\n",
       "      <td>[0.0, 0.5309729999999999, 1.0619459999999998, ...</td>\n",
       "      <td>[0.0, 8.495567999999999, 25.486704, 42.4753280...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003_6foot7foot</td>\n",
       "      <td>bars/harmonix/0003_6foot7foot.npy</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0003_6foot7foot, 0003_6foot7foot, 0003_6foot7...</td>\n",
       "      <td>[2.857108, 3.571394, 4.28568, 4.99996600000000...</td>\n",
       "      <td>[2.857108, 8.571396, 31.428548, 37.14283599999...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004_abc</td>\n",
       "      <td>bars/harmonix/0004_abc.npy</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0004_abc, 0004_abc, 0004_abc, 0004_abc, 0004_...</td>\n",
       "      <td>[2.666656, 3.238084, 3.952369, 4.597529, 5.242...</td>\n",
       "      <td>[2.666656, 28.300542999999998, 58.263180000000...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006_aint2proud2beg</td>\n",
       "      <td>bars/harmonix/0006_aint2proud2beg.npy</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0006_aint2proud2beg, 0006_aint2proud2beg, 000...</td>\n",
       "      <td>[0.0, 0.572203, 1.144406, 1.716609, 2.288812, ...</td>\n",
       "      <td>[0.0, 27.4652, 45.203726, 63.518522999999995, ...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008_america</td>\n",
       "      <td>bars/harmonix/0008_america.npy</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0008_america, 0008_america, 0008_america, 000...</td>\n",
       "      <td>[3.871208, 4.359011, 4.846814, 5.338616, 5.830...</td>\n",
       "      <td>[3.871208, 10.56504, 33.217138, 56.85190400000...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  File                          Sub_Divisions  \\\n",
       "0          0001_12step          bars/harmonix/0001_12step.npy   \n",
       "1      0003_6foot7foot      bars/harmonix/0003_6foot7foot.npy   \n",
       "2             0004_abc             bars/harmonix/0004_abc.npy   \n",
       "3  0006_aint2proud2beg  bars/harmonix/0006_aint2proud2beg.npy   \n",
       "4         0008_america         bars/harmonix/0008_america.npy   \n",
       "\n",
       "                                       Binary_Labels  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     Weighted_Labels  \\\n",
       "0  [1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                             Weights  \\\n",
       "0  [3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, ...   \n",
       "1  [3.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2  [3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                                 IDS  \\\n",
       "0  [0001_12step, 0001_12step, 0001_12step, 0001_1...   \n",
       "1  [0003_6foot7foot, 0003_6foot7foot, 0003_6foot7...   \n",
       "2  [0004_abc, 0004_abc, 0004_abc, 0004_abc, 0004_...   \n",
       "3  [0006_aint2proud2beg, 0006_aint2proud2beg, 000...   \n",
       "4  [0008_america, 0008_america, 0008_america, 000...   \n",
       "\n",
       "                                          Beat_times  \\\n",
       "0  [0.0, 0.5309729999999999, 1.0619459999999998, ...   \n",
       "1  [2.857108, 3.571394, 4.28568, 4.99996600000000...   \n",
       "2  [2.666656, 3.238084, 3.952369, 4.597529, 5.242...   \n",
       "3  [0.0, 0.572203, 1.144406, 1.716609, 2.288812, ...   \n",
       "4  [3.871208, 4.359011, 4.846814, 5.338616, 5.830...   \n",
       "\n",
       "                                              Labels  BPM  \n",
       "0  [0.0, 8.495567999999999, 25.486704, 42.4753280...  113  \n",
       "1  [2.857108, 8.571396, 31.428548, 37.14283599999...   84  \n",
       "2  [2.666656, 28.300542999999998, 58.263180000000...   94  \n",
       "3  [0.0, 27.4652, 45.203726, 63.518522999999995, ...  105  \n",
       "4  [3.871208, 10.56504, 33.217138, 56.85190400000...  136  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if COLAB:\n",
    "    harmonix_beats = pickle.load(open(os.path.join(ROOT, SUB_DIVS_DIR, 'bars', 'harmonix.p'), 'rb'))\n",
    "else:\n",
    "    harmonix_beats = pd.read_pickle(os.path.join(ROOT, SUB_DIVS_DIR, 'bars', 'harmonix.p'))\n",
    "harmonix_beats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Mel Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_np(file):\n",
    "    return np.load(os.path.join(ROOT, SUB_DIVS_DIR, file), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 885/885 [01:42<00:00,  8.60it/s]\n"
     ]
    }
   ],
   "source": [
    "harmonix_beats['Sub_Divisions'] = harmonix_beats['Sub_Divisions'].progress_map(load_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = harmonix_beats.copy()\n",
    "y = harmonix_beats['Binary_Labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, _, _ = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, _, _ = train_test_split(X_train, X_train['Binary_Labels'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.concatenate(X_train['Over_Labels'].values)\n",
    "y_train = np.concatenate(X_train['Binary_Labels'].values)\n",
    "y_test = np.concatenate(X_test['Binary_Labels'].values)\n",
    "y_val = np.concatenate(X_val['Binary_Labels'].values)\n",
    "\n",
    "ids_test = np.concatenate(X_test['IDS'].values)\n",
    "\n",
    "# w_train = np.concatenate(X_train['Over_Weights'].values)\n",
    "w_train = np.concatenate(X_train['Weights'].values)\n",
    "w_test = np.concatenate(X_test['Weights'].values)\n",
    "w_val = np.concatenate(X_val['Weights'].values)\n",
    "\n",
    "# X_train = np.concatenate(X_train['Oversamples'].values)\n",
    "X_train = np.concatenate(X_train['Sub_Divisions'].values)\n",
    "X_test = np.concatenate(X_test['Sub_Divisions'].values)\n",
    "X_val = np.concatenate(X_val['Sub_Divisions'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 5817, 0.0: 52623})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Initial Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial bias: [-2.20236862]\n"
     ]
    }
   ],
   "source": [
    "count = np.bincount(y_train.astype('int64'))\n",
    "neg, pos = count[0], count[1]\n",
    "total = neg + pos\n",
    "initial_bias = np.log([pos/neg])\n",
    "print(f'Initial bias: {initial_bias}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(initial_bias):\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "    bias_initializer = tf.keras.initializers.Constant(initial_bias)\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "    return Sequential([\n",
    "        Input(shape=(N_MELS, 4, 33)),\n",
    "        Conv2D(8, 8, activation='relu', kernel_initializer=initializer, padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(5, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Conv2D(16, 6, activation='relu', padding=\"same\", kernel_initializer=initializer),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='sigmoid'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid', bias_initializer=bias_initializer)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3814\n",
      "Epoch 1/80\n",
      "457/457 [==============================] - 50s 107ms/step - loss: 0.5358 - accuracy: 0.5328 - precision: 0.3370 - recall: 0.4198 - auc: 0.7703 - val_loss: 0.2262 - val_accuracy: 0.8548 - val_precision: 0.5871 - val_recall: 0.4366 - val_auc: 0.8844\n",
      "Epoch 2/80\n",
      "457/457 [==============================] - 41s 90ms/step - loss: 0.4431 - accuracy: 0.6813 - precision: 0.3996 - recall: 0.6065 - auc: 0.8541 - val_loss: 0.2111 - val_accuracy: 0.8567 - val_precision: 0.6500 - val_recall: 0.4558 - val_auc: 0.8969\n",
      "Epoch 3/80\n",
      "457/457 [==============================] - 44s 96ms/step - loss: 0.4152 - accuracy: 0.7130 - precision: 0.4238 - recall: 0.6421 - auc: 0.8726 - val_loss: 0.2473 - val_accuracy: 0.7687 - val_precision: 0.5199 - val_recall: 0.6717 - val_auc: 0.9106\n",
      "Epoch 4/80\n",
      "457/457 [==============================] - 102s 224ms/step - loss: 0.4018 - accuracy: 0.7207 - precision: 0.4271 - recall: 0.6457 - auc: 0.8828 - val_loss: 0.2282 - val_accuracy: 0.8211 - val_precision: 0.5428 - val_recall: 0.6429 - val_auc: 0.9038\n",
      "Epoch 5/80\n",
      "457/457 [==============================] - 100s 218ms/step - loss: 0.3878 - accuracy: 0.7276 - precision: 0.4501 - recall: 0.6746 - auc: 0.8907 - val_loss: 0.2218 - val_accuracy: 0.8265 - val_precision: 0.5772 - val_recall: 0.6203 - val_auc: 0.9081\n",
      "Epoch 6/80\n",
      "457/457 [==============================] - 44s 97ms/step - loss: 0.3828 - accuracy: 0.7267 - precision: 0.4504 - recall: 0.6777 - auc: 0.8936 - val_loss: 0.2097 - val_accuracy: 0.8555 - val_precision: 0.5965 - val_recall: 0.5764 - val_auc: 0.9089\n",
      "Epoch 7/80\n",
      "457/457 [==============================] - 40s 86ms/step - loss: 0.3741 - accuracy: 0.7315 - precision: 0.4635 - recall: 0.6857 - auc: 0.8988 - val_loss: 0.2233 - val_accuracy: 0.8329 - val_precision: 0.5543 - val_recall: 0.6155 - val_auc: 0.9061\n",
      "Epoch 8/80\n",
      "457/457 [==============================] - 41s 90ms/step - loss: 0.3680 - accuracy: 0.7318 - precision: 0.4710 - recall: 0.6968 - auc: 0.9021 - val_loss: 0.2041 - val_accuracy: 0.8575 - val_precision: 0.6137 - val_recall: 0.5826 - val_auc: 0.9124\n",
      "Epoch 9/80\n",
      "457/457 [==============================] - 44s 97ms/step - loss: 0.3623 - accuracy: 0.7383 - precision: 0.4719 - recall: 0.6914 - auc: 0.9054 - val_loss: 0.2314 - val_accuracy: 0.8195 - val_precision: 0.5263 - val_recall: 0.6648 - val_auc: 0.9076\n",
      "Epoch 10/80\n",
      "457/457 [==============================] - 44s 97ms/step - loss: 0.3583 - accuracy: 0.7396 - precision: 0.4803 - recall: 0.6973 - auc: 0.9074 - val_loss: 0.2087 - val_accuracy: 0.8554 - val_precision: 0.5996 - val_recall: 0.6374 - val_auc: 0.9165\n",
      "Epoch 11/80\n",
      "457/457 [==============================] - 41s 91ms/step - loss: 0.3557 - accuracy: 0.7448 - precision: 0.4762 - recall: 0.7065 - auc: 0.9094 - val_loss: 0.2218 - val_accuracy: 0.8143 - val_precision: 0.5511 - val_recall: 0.6758 - val_auc: 0.9157\n",
      "Epoch 12/80\n",
      "457/457 [==============================] - 40s 88ms/step - loss: 0.3535 - accuracy: 0.7447 - precision: 0.4794 - recall: 0.7064 - auc: 0.9102 - val_loss: 0.2113 - val_accuracy: 0.8454 - val_precision: 0.5773 - val_recall: 0.6347 - val_auc: 0.9138\n",
      "Epoch 13/80\n",
      "457/457 [==============================] - 42s 92ms/step - loss: 0.3509 - accuracy: 0.7457 - precision: 0.4833 - recall: 0.7162 - auc: 0.9115 - val_loss: 0.2154 - val_accuracy: 0.8223 - val_precision: 0.5631 - val_recall: 0.6854 - val_auc: 0.9187\n",
      "Epoch 14/80\n",
      "457/457 [==============================] - 41s 90ms/step - loss: 0.3450 - accuracy: 0.7511 - precision: 0.4881 - recall: 0.7215 - auc: 0.9147 - val_loss: 0.2280 - val_accuracy: 0.8262 - val_precision: 0.5373 - val_recall: 0.6916 - val_auc: 0.9173\n",
      "Epoch 15/80\n",
      "457/457 [==============================] - 40s 88ms/step - loss: 0.3447 - accuracy: 0.7515 - precision: 0.4885 - recall: 0.7148 - auc: 0.9147 - val_loss: 0.2100 - val_accuracy: 0.8486 - val_precision: 0.5900 - val_recall: 0.6045 - val_auc: 0.9124\n",
      "Epoch 16/80\n",
      "457/457 [==============================] - 40s 88ms/step - loss: 0.3425 - accuracy: 0.7520 - precision: 0.4894 - recall: 0.7258 - auc: 0.9164 - val_loss: 0.2119 - val_accuracy: 0.8491 - val_precision: 0.5707 - val_recall: 0.6498 - val_auc: 0.9188\n",
      "Epoch 17/80\n",
      "457/457 [==============================] - 40s 86ms/step - loss: 0.3429 - accuracy: 0.7520 - precision: 0.4846 - recall: 0.7224 - auc: 0.9158 - val_loss: 0.2098 - val_accuracy: 0.8438 - val_precision: 0.5721 - val_recall: 0.6552 - val_auc: 0.9171\n",
      "Epoch 18/80\n",
      "457/457 [==============================] - 40s 88ms/step - loss: 0.3372 - accuracy: 0.7585 - precision: 0.4891 - recall: 0.7279 - auc: 0.9184 - val_loss: 0.2098 - val_accuracy: 0.8485 - val_precision: 0.5803 - val_recall: 0.6587 - val_auc: 0.9188\n",
      "Epoch 19/80\n",
      "457/457 [==============================] - 42s 91ms/step - loss: 0.3379 - accuracy: 0.7559 - precision: 0.4863 - recall: 0.7279 - auc: 0.9189 - val_loss: 0.2187 - val_accuracy: 0.8186 - val_precision: 0.5399 - val_recall: 0.6772 - val_auc: 0.9149\n",
      "Epoch 20/80\n",
      "457/457 [==============================] - 40s 88ms/step - loss: 0.3331 - accuracy: 0.7599 - precision: 0.4909 - recall: 0.7397 - auc: 0.9211 - val_loss: 0.2207 - val_accuracy: 0.8129 - val_precision: 0.5459 - val_recall: 0.6847 - val_auc: 0.9170\n",
      "Epoch 21/80\n",
      "457/457 [==============================] - 39s 86ms/step - loss: 0.3347 - accuracy: 0.7568 - precision: 0.4932 - recall: 0.7318 - auc: 0.9198 - val_loss: 0.2006 - val_accuracy: 0.8569 - val_precision: 0.6098 - val_recall: 0.6073 - val_auc: 0.9174\n",
      "Epoch 22/80\n",
      "457/457 [==============================] - 40s 87ms/step - loss: 0.3326 - accuracy: 0.7627 - precision: 0.4966 - recall: 0.7347 - auc: 0.9208 - val_loss: 0.2094 - val_accuracy: 0.8421 - val_precision: 0.5774 - val_recall: 0.6491 - val_auc: 0.9188\n",
      "Epoch 23/80\n",
      "457/457 [==============================] - 40s 87ms/step - loss: 0.3307 - accuracy: 0.7633 - precision: 0.4869 - recall: 0.7413 - auc: 0.9221 - val_loss: 0.2086 - val_accuracy: 0.8443 - val_precision: 0.5760 - val_recall: 0.6751 - val_auc: 0.9191\n",
      "Epoch 24/80\n",
      "457/457 [==============================] - 40s 87ms/step - loss: 0.3289 - accuracy: 0.7647 - precision: 0.4964 - recall: 0.7425 - auc: 0.9226 - val_loss: 0.2174 - val_accuracy: 0.8388 - val_precision: 0.5638 - val_recall: 0.6909 - val_auc: 0.9225\n",
      "Epoch 25/80\n",
      "457/457 [==============================] - 40s 88ms/step - loss: 0.3273 - accuracy: 0.7614 - precision: 0.4991 - recall: 0.7445 - auc: 0.9237 - val_loss: 0.2180 - val_accuracy: 0.8391 - val_precision: 0.5622 - val_recall: 0.6881 - val_auc: 0.9191\n",
      "Epoch 26/80\n",
      "457/457 [==============================] - 41s 89ms/step - loss: 0.3250 - accuracy: 0.7665 - precision: 0.4946 - recall: 0.7427 - auc: 0.9247 - val_loss: 0.2187 - val_accuracy: 0.8402 - val_precision: 0.5667 - val_recall: 0.6840 - val_auc: 0.9173\n",
      "Epoch 27/80\n",
      "457/457 [==============================] - 58s 127ms/step - loss: 0.3245 - accuracy: 0.7676 - precision: 0.4995 - recall: 0.7492 - auc: 0.9253 - val_loss: 0.2379 - val_accuracy: 0.8101 - val_precision: 0.5119 - val_recall: 0.7217 - val_auc: 0.9184\n",
      "Epoch 28/80\n",
      "457/457 [==============================] - 50s 109ms/step - loss: 0.3239 - accuracy: 0.7684 - precision: 0.4988 - recall: 0.7499 - auc: 0.9253 - val_loss: 0.2143 - val_accuracy: 0.8407 - val_precision: 0.5640 - val_recall: 0.6703 - val_auc: 0.9165\n",
      "Epoch 29/80\n",
      "457/457 [==============================] - 41s 90ms/step - loss: 0.3223 - accuracy: 0.7684 - precision: 0.5047 - recall: 0.7542 - auc: 0.9263 - val_loss: 0.2038 - val_accuracy: 0.8663 - val_precision: 0.6065 - val_recall: 0.6223 - val_auc: 0.9190\n",
      "Epoch 30/80\n",
      "457/457 [==============================] - 40s 88ms/step - loss: 0.3216 - accuracy: 0.7690 - precision: 0.5032 - recall: 0.7468 - auc: 0.9264 - val_loss: 0.2085 - val_accuracy: 0.8603 - val_precision: 0.5813 - val_recall: 0.6395 - val_auc: 0.9203\n",
      "Epoch 31/80\n",
      "457/457 [==============================] - 40s 88ms/step - loss: 0.3235 - accuracy: 0.7663 - precision: 0.5028 - recall: 0.7464 - auc: 0.9255 - val_loss: 0.2135 - val_accuracy: 0.8322 - val_precision: 0.5637 - val_recall: 0.6765 - val_auc: 0.9190\n",
      "Epoch 32/80\n",
      "457/457 [==============================] - 42s 92ms/step - loss: 0.3186 - accuracy: 0.7713 - precision: 0.5071 - recall: 0.7561 - auc: 0.9278 - val_loss: 0.2058 - val_accuracy: 0.8552 - val_precision: 0.5866 - val_recall: 0.6361 - val_auc: 0.9200\n",
      "Epoch 33/80\n",
      "457/457 [==============================] - 41s 89ms/step - loss: 0.3188 - accuracy: 0.7728 - precision: 0.5032 - recall: 0.7511 - auc: 0.9278 - val_loss: 0.2054 - val_accuracy: 0.8633 - val_precision: 0.5901 - val_recall: 0.6265 - val_auc: 0.9198\n",
      "Epoch 34/80\n",
      "457/457 [==============================] - 40s 87ms/step - loss: 0.3182 - accuracy: 0.7732 - precision: 0.5096 - recall: 0.7500 - auc: 0.9280 - val_loss: 0.2013 - val_accuracy: 0.8585 - val_precision: 0.5996 - val_recall: 0.6374 - val_auc: 0.9216\n",
      "Epoch 35/80\n",
      "457/457 [==============================] - 42s 92ms/step - loss: 0.3194 - accuracy: 0.7681 - precision: 0.5003 - recall: 0.7521 - auc: 0.9275 - val_loss: 0.2115 - val_accuracy: 0.8614 - val_precision: 0.5831 - val_recall: 0.6491 - val_auc: 0.9186\n",
      "Epoch 36/80\n",
      "457/457 [==============================] - 41s 89ms/step - loss: 0.3173 - accuracy: 0.7729 - precision: 0.5049 - recall: 0.7586 - auc: 0.9280 - val_loss: 0.2098 - val_accuracy: 0.8603 - val_precision: 0.5853 - val_recall: 0.6539 - val_auc: 0.9196\n",
      "Epoch 37/80\n",
      "457/457 [==============================] - 43s 93ms/step - loss: 0.3120 - accuracy: 0.7786 - precision: 0.5065 - recall: 0.7609 - auc: 0.9310 - val_loss: 0.2034 - val_accuracy: 0.8541 - val_precision: 0.6021 - val_recall: 0.6388 - val_auc: 0.9175\n",
      "Epoch 38/80\n",
      "457/457 [==============================] - 42s 92ms/step - loss: 0.3138 - accuracy: 0.7733 - precision: 0.5050 - recall: 0.7562 - auc: 0.9298 - val_loss: 0.2232 - val_accuracy: 0.8498 - val_precision: 0.5524 - val_recall: 0.6895 - val_auc: 0.9209\n",
      "Epoch 39/80\n",
      "457/457 [==============================] - 40s 88ms/step - loss: 0.3124 - accuracy: 0.7778 - precision: 0.5084 - recall: 0.7631 - auc: 0.9306 - val_loss: 0.2089 - val_accuracy: 0.8632 - val_precision: 0.5870 - val_recall: 0.6450 - val_auc: 0.9192\n",
      "Epoch 40/80\n",
      "457/457 [==============================] - 41s 89ms/step - loss: 0.3113 - accuracy: 0.7772 - precision: 0.5106 - recall: 0.7626 - auc: 0.9309 - val_loss: 0.2147 - val_accuracy: 0.8535 - val_precision: 0.5650 - val_recall: 0.6765 - val_auc: 0.9180\n",
      "Epoch 41/80\n",
      "457/457 [==============================] - 40s 87ms/step - loss: 0.3090 - accuracy: 0.7830 - precision: 0.5099 - recall: 0.7643 - auc: 0.9323 - val_loss: 0.2230 - val_accuracy: 0.8265 - val_precision: 0.5385 - val_recall: 0.7101 - val_auc: 0.9207\n",
      "Epoch 42/80\n",
      "457/457 [==============================] - 40s 87ms/step - loss: 0.3046 - accuracy: 0.7810 - precision: 0.5090 - recall: 0.7705 - auc: 0.9341 - val_loss: 0.2117 - val_accuracy: 0.8481 - val_precision: 0.5726 - val_recall: 0.6676 - val_auc: 0.9186\n",
      "Epoch 43/80\n",
      "457/457 [==============================] - 40s 88ms/step - loss: 0.3110 - accuracy: 0.7778 - precision: 0.5144 - recall: 0.7633 - auc: 0.9313 - val_loss: 0.2072 - val_accuracy: 0.8508 - val_precision: 0.5773 - val_recall: 0.6504 - val_auc: 0.9190\n",
      "Epoch 44/80\n",
      "457/457 [==============================] - 41s 89ms/step - loss: 0.3126 - accuracy: 0.7775 - precision: 0.5041 - recall: 0.7622 - auc: 0.9305 - val_loss: 0.2115 - val_accuracy: 0.8487 - val_precision: 0.5659 - val_recall: 0.6765 - val_auc: 0.9202\n"
     ]
    }
   ],
   "source": [
    "model = build_model(initial_bias)\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.05, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=get_metrics())\n",
    "\n",
    "results = model.evaluate(X_test, y_test, batch_size=32, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=20, mode='max', restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size=128,\n",
    "    epochs=80, \n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    sample_weight=w_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18696/18696 [==============================] - 12s 617us/step\n",
      "585/585 [==============================] - 2s 4ms/step - loss: 0.2267 - accuracy: 0.8320 - precision: 0.5307 - recall: 0.6804 - auc: 0.9109\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, batch_size=1, verbose=1)\n",
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     16853\n",
      "         1.0       0.53      0.68      0.60      1843\n",
      "\n",
      "    accuracy                           0.91     18696\n",
      "   macro avg       0.75      0.81      0.77     18696\n",
      "weighted avg       0.92      0.91      0.91     18696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [1 if (p > 0.5) else 0 for p in preds]\n",
    "y_pred = np.asarray(y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score:  0.2548152878649546\n",
      "Precision:  0.24800795861619115\n",
      "Recall:  0.2741267940302416\n"
     ]
    }
   ],
   "source": [
    "f_score, precision, recall = evaluate(harmonix_beats, preds, ids_test, True, window=0.5)\n",
    "\n",
    "print(\"F-score: \", f_score)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best score\n",
    " * Every iteration of this notebook has a different result\n",
    " * The best score achieved is reported below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "3 seconds:\n",
    "F-score:  0.7079411816253922\n",
    "Precision:  0.7491938013677144\n",
    "Recall:  0.7204761904761905\n",
    "\n",
    "0.5 seconds:\n",
    "F-score:  0.3044451156585869\n",
    "Precision:  0.2801110180142438\n",
    "Recall:  0.35031746031746025\n",
    "\n",
    "2 bars:\n",
    "F-score:  0.7391024180497865\n",
    "Precision:  0.7825271347010477\n",
    "Recall:  0.7499206349206349\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best score architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model = Sequential([\n",
    "    Input(shape=(N_MELS, 4, 33)),\n",
    "    Conv2D(8, 8, activation='relu', kernel_initializer=initializer, padding=\"same\"),\n",
    "    MaxPooling2D(pool_size=(5, 2)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(16, 6, activation='relu', padding=\"same\", kernel_initializer=initializer),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='sigmoid'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid', bias_initializer=bias_initializer)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(ROOT, 'models', 'full_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(ROOT, 'data', '06_Results', 'harmonix_full.npz'), preds=preds, ids=ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
