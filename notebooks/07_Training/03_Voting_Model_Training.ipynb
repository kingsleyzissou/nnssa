{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT = '/content/drive/MyDrive/fyp/collabs/'\n",
    "else:\n",
    "    ROOT = os.path.join(os.getcwd(), '..', '..') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Colab libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    !pip install pickle5\n",
    "    import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load custom modules"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install git+https://github.com/kingsleyzissou/nnssa.git@0.1.1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install mir_eval peakutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnssa.constants import *\n",
    "from nnssa.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TensorFlow modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics():\n",
    "    return [\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.15),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('COLAB_TPU_ADDR' in os.environ.keys()):\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "    tf.config.experimental_connect_to_host(resolver.master())\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress bars!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Sub_Divisions</th>\n",
       "      <th>Binary_Labels</th>\n",
       "      <th>Weighted_Labels</th>\n",
       "      <th>Weights</th>\n",
       "      <th>IDS</th>\n",
       "      <th>Beat_times</th>\n",
       "      <th>Labels</th>\n",
       "      <th>BPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_12step</td>\n",
       "      <td>bars/harmonix/0001_12step.npy</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0001_12step, 0001_12step, 0001_12step, 0001_1...</td>\n",
       "      <td>[0.0, 0.5309729999999999, 1.0619459999999998, ...</td>\n",
       "      <td>[0.0, 8.495567999999999, 25.486704, 42.4753280...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003_6foot7foot</td>\n",
       "      <td>bars/harmonix/0003_6foot7foot.npy</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0003_6foot7foot, 0003_6foot7foot, 0003_6foot7...</td>\n",
       "      <td>[2.857108, 3.571394, 4.28568, 4.99996600000000...</td>\n",
       "      <td>[2.857108, 8.571396, 31.428548, 37.14283599999...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004_abc</td>\n",
       "      <td>bars/harmonix/0004_abc.npy</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0004_abc, 0004_abc, 0004_abc, 0004_abc, 0004_...</td>\n",
       "      <td>[2.666656, 3.238084, 3.952369, 4.597529, 5.242...</td>\n",
       "      <td>[2.666656, 28.300542999999998, 58.263180000000...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006_aint2proud2beg</td>\n",
       "      <td>bars/harmonix/0006_aint2proud2beg.npy</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0006_aint2proud2beg, 0006_aint2proud2beg, 000...</td>\n",
       "      <td>[0.0, 0.572203, 1.144406, 1.716609, 2.288812, ...</td>\n",
       "      <td>[0.0, 27.4652, 45.203726, 63.518522999999995, ...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008_america</td>\n",
       "      <td>bars/harmonix/0008_america.npy</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0008_america, 0008_america, 0008_america, 000...</td>\n",
       "      <td>[3.871208, 4.359011, 4.846814, 5.338616, 5.830...</td>\n",
       "      <td>[3.871208, 10.56504, 33.217138, 56.85190400000...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  File                          Sub_Divisions  \\\n",
       "0          0001_12step          bars/harmonix/0001_12step.npy   \n",
       "1      0003_6foot7foot      bars/harmonix/0003_6foot7foot.npy   \n",
       "2             0004_abc             bars/harmonix/0004_abc.npy   \n",
       "3  0006_aint2proud2beg  bars/harmonix/0006_aint2proud2beg.npy   \n",
       "4         0008_america         bars/harmonix/0008_america.npy   \n",
       "\n",
       "                                       Binary_Labels  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     Weighted_Labels  \\\n",
       "0  [1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                             Weights  \\\n",
       "0  [3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, ...   \n",
       "1  [3.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2  [3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                                 IDS  \\\n",
       "0  [0001_12step, 0001_12step, 0001_12step, 0001_1...   \n",
       "1  [0003_6foot7foot, 0003_6foot7foot, 0003_6foot7...   \n",
       "2  [0004_abc, 0004_abc, 0004_abc, 0004_abc, 0004_...   \n",
       "3  [0006_aint2proud2beg, 0006_aint2proud2beg, 000...   \n",
       "4  [0008_america, 0008_america, 0008_america, 000...   \n",
       "\n",
       "                                          Beat_times  \\\n",
       "0  [0.0, 0.5309729999999999, 1.0619459999999998, ...   \n",
       "1  [2.857108, 3.571394, 4.28568, 4.99996600000000...   \n",
       "2  [2.666656, 3.238084, 3.952369, 4.597529, 5.242...   \n",
       "3  [0.0, 0.572203, 1.144406, 1.716609, 2.288812, ...   \n",
       "4  [3.871208, 4.359011, 4.846814, 5.338616, 5.830...   \n",
       "\n",
       "                                              Labels  BPM  \n",
       "0  [0.0, 8.495567999999999, 25.486704, 42.4753280...  113  \n",
       "1  [2.857108, 8.571396, 31.428548, 37.14283599999...   84  \n",
       "2  [2.666656, 28.300542999999998, 58.263180000000...   94  \n",
       "3  [0.0, 27.4652, 45.203726, 63.518522999999995, ...  105  \n",
       "4  [3.871208, 10.56504, 33.217138, 56.85190400000...  136  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if COLAB:\n",
    "    harmonix_beats = pickle.load(open(os.path.join(ROOT, SUB_DIVS_DIR, 'bars', 'harmonix.p'), 'rb'))\n",
    "else:\n",
    "    harmonix_beats = pd.read_pickle(os.path.join(ROOT, SUB_DIVS_DIR, 'bars', 'harmonix.p'))\n",
    "harmonix_beats = harmonix_beats.head(100)\n",
    "harmonix_beats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Mel Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_np(file):\n",
    "    return np.load(os.path.join(ROOT, SUB_DIVS_DIR, file), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.33it/s]\n"
     ]
    }
   ],
   "source": [
    "harmonix_beats['Sub_Divisions'] = harmonix_beats['Sub_Divisions'].progress_map(load_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = harmonix_beats.copy()\n",
    "y = harmonix_beats['Binary_Labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, _, _ = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, _, _ = train_test_split(X_train, X_train['Binary_Labels'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate(X_train['Binary_Labels'].values)\n",
    "y_test = np.concatenate(X_test['Binary_Labels'].values)\n",
    "y_val = np.concatenate(X_val['Binary_Labels'].values)\n",
    "\n",
    "ids_test = np.concatenate(X_test['IDS'].values)\n",
    "\n",
    "w_train = np.concatenate(X_train['Weights'].values)\n",
    "w_test = np.concatenate(X_test['Weights'].values)\n",
    "w_val = np.concatenate(X_val['Weights'].values)\n",
    "\n",
    "X_train = np.concatenate(X_train['Sub_Divisions'].values)\n",
    "X_test = np.concatenate(X_test['Sub_Divisions'].values)\n",
    "X_val = np.concatenate(X_val['Sub_Divisions'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 566, 0.0: 5654})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Initial Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bias(y):\n",
    "    count = np.bincount(y.astype('int64'))\n",
    "    neg, pos = count[0], count[1]\n",
    "    total = neg + pos\n",
    "    return np.log([pos/neg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(initial_bias, rand):\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "    bias_initializer = tf.keras.initializers.Constant(initial_bias)\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "    neurons = [[8, 16, 256], [8, 16, 128], [8, 16, 128], [8, 16, 128], [8, 16, 256],]\n",
    "    first_neuron, second_neuron, third_neuron = neurons[rand]\n",
    "    print(first_neuron, second_neuron, third_neuron)\n",
    "    return Sequential([\n",
    "        Input(shape=(N_MELS, 4, 33)),\n",
    "        Conv2D(first_neuron, 8, activation='relu', kernel_initializer=initializer, padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(5, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Conv2D(second_neuron, 6, activation='relu', padding=\"same\", kernel_initializer=initializer),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Flatten(),\n",
    "        Dense(third_neuron, activation='sigmoid'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid', bias_initializer=bias_initializer)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIY Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_sample(X_train, y_train, w_train):\n",
    "    n = X_train.shape[0]\n",
    "    samples = np.random.choice(n, size=n)\n",
    "    return X_train[samples, :, :, :], y_train[samples], w_train[samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 16 256\n",
      "Training model 0\n",
      "Epoch 1/80\n",
      "49/49 [==============================] - 6s 109ms/step - loss: 0.7046 - accuracy: 0.3952 - precision: 0.1187 - recall: 0.1118 - auc: 0.5349 - val_loss: 0.5295 - val_accuracy: 0.1300 - val_precision: 0.1889 - val_recall: 0.4265 - val_auc: 0.6676\n",
      "Epoch 2/80\n",
      "49/49 [==============================] - 5s 92ms/step - loss: 0.6335 - accuracy: 0.4502 - precision: 0.1988 - recall: 0.2551 - auc: 0.6380 - val_loss: 0.2777 - val_accuracy: 0.7268 - val_precision: 0.3495 - val_recall: 0.2647 - val_auc: 0.7814\n",
      "Epoch 3/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.5240 - accuracy: 0.6525 - precision: 0.2901 - recall: 0.3447 - auc: 0.7557 - val_loss: 0.3862 - val_accuracy: 0.6094 - val_precision: 0.2923 - val_recall: 0.6103 - val_auc: 0.8294\n",
      "Epoch 4/80\n",
      "49/49 [==============================] - 5s 92ms/step - loss: 0.4552 - accuracy: 0.6797 - precision: 0.3706 - recall: 0.5303 - auc: 0.8365 - val_loss: 0.2566 - val_accuracy: 0.7666 - val_precision: 0.4049 - val_recall: 0.4853 - val_auc: 0.8571\n",
      "Epoch 5/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.4197 - accuracy: 0.7242 - precision: 0.3987 - recall: 0.5871 - auc: 0.8675 - val_loss: 0.3734 - val_accuracy: 0.6578 - val_precision: 0.3235 - val_recall: 0.7279 - val_auc: 0.8607\n",
      "Epoch 6/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.3800 - accuracy: 0.7398 - precision: 0.4218 - recall: 0.6436 - auc: 0.8901 - val_loss: 0.3209 - val_accuracy: 0.6969 - val_precision: 0.3629 - val_recall: 0.6618 - val_auc: 0.8552\n",
      "Epoch 7/80\n",
      "49/49 [==============================] - 4s 87ms/step - loss: 0.3440 - accuracy: 0.7738 - precision: 0.4583 - recall: 0.7113 - auc: 0.9104 - val_loss: 0.3607 - val_accuracy: 0.6757 - val_precision: 0.3333 - val_recall: 0.6765 - val_auc: 0.8584\n",
      "Epoch 8/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.3383 - accuracy: 0.7702 - precision: 0.4505 - recall: 0.6979 - auc: 0.9148 - val_loss: 0.2493 - val_accuracy: 0.8462 - val_precision: 0.4357 - val_recall: 0.4485 - val_auc: 0.8655\n",
      "Epoch 9/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.2979 - accuracy: 0.8110 - precision: 0.5194 - recall: 0.7395 - auc: 0.9340 - val_loss: 0.4280 - val_accuracy: 0.7248 - val_precision: 0.2910 - val_recall: 0.6397 - val_auc: 0.8412\n",
      "Epoch 10/80\n",
      "49/49 [==============================] - 5s 92ms/step - loss: 0.3320 - accuracy: 0.7938 - precision: 0.4521 - recall: 0.7474 - auc: 0.9218 - val_loss: 0.2917 - val_accuracy: 0.8389 - val_precision: 0.4101 - val_recall: 0.5368 - val_auc: 0.8631\n",
      "Epoch 11/80\n",
      "49/49 [==============================] - 4s 86ms/step - loss: 0.2863 - accuracy: 0.8330 - precision: 0.5039 - recall: 0.7680 - auc: 0.9369 - val_loss: 0.2828 - val_accuracy: 0.8077 - val_precision: 0.3897 - val_recall: 0.5588 - val_auc: 0.8674\n",
      "Epoch 12/80\n",
      "49/49 [==============================] - 4s 87ms/step - loss: 0.2827 - accuracy: 0.8276 - precision: 0.5215 - recall: 0.7769 - auc: 0.9397 - val_loss: 0.3096 - val_accuracy: 0.8667 - val_precision: 0.4126 - val_recall: 0.4338 - val_auc: 0.8310\n",
      "Epoch 13/80\n",
      "49/49 [==============================] - 4s 87ms/step - loss: 0.2949 - accuracy: 0.8306 - precision: 0.5187 - recall: 0.7703 - auc: 0.9395 - val_loss: 0.3233 - val_accuracy: 0.8329 - val_precision: 0.3979 - val_recall: 0.5588 - val_auc: 0.8536\n",
      "Epoch 14/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.3162 - accuracy: 0.8375 - precision: 0.5083 - recall: 0.7720 - auc: 0.9323 - val_loss: 0.2441 - val_accuracy: 0.8826 - val_precision: 0.5455 - val_recall: 0.3529 - val_auc: 0.8690\n",
      "Epoch 15/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.2828 - accuracy: 0.8498 - precision: 0.5591 - recall: 0.7966 - auc: 0.9424 - val_loss: 0.3710 - val_accuracy: 0.7659 - val_precision: 0.3556 - val_recall: 0.7059 - val_auc: 0.8612\n",
      "Epoch 16/80\n",
      "49/49 [==============================] - 4s 87ms/step - loss: 0.2576 - accuracy: 0.8401 - precision: 0.5116 - recall: 0.8327 - auc: 0.9525 - val_loss: 0.2965 - val_accuracy: 0.8249 - val_precision: 0.3961 - val_recall: 0.6029 - val_auc: 0.8679\n",
      "Epoch 17/80\n",
      "49/49 [==============================] - 4s 83ms/step - loss: 0.2311 - accuracy: 0.8594 - precision: 0.5879 - recall: 0.8477 - auc: 0.9593 - val_loss: 0.2630 - val_accuracy: 0.8462 - val_precision: 0.4702 - val_recall: 0.5809 - val_auc: 0.8615\n",
      "Epoch 18/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2247 - accuracy: 0.8623 - precision: 0.5831 - recall: 0.8339 - auc: 0.9621 - val_loss: 0.2575 - val_accuracy: 0.8594 - val_precision: 0.4487 - val_recall: 0.5147 - val_auc: 0.8786\n",
      "Epoch 19/80\n",
      "49/49 [==============================] - 4s 87ms/step - loss: 0.2103 - accuracy: 0.8716 - precision: 0.5899 - recall: 0.8574 - auc: 0.9636 - val_loss: 0.2950 - val_accuracy: 0.8667 - val_precision: 0.4741 - val_recall: 0.4706 - val_auc: 0.8384\n",
      "Epoch 20/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2191 - accuracy: 0.8693 - precision: 0.5839 - recall: 0.8521 - auc: 0.9646 - val_loss: 0.2890 - val_accuracy: 0.8568 - val_precision: 0.4606 - val_recall: 0.5588 - val_auc: 0.8592\n",
      "Epoch 21/80\n",
      "49/49 [==============================] - 5s 99ms/step - loss: 0.2432 - accuracy: 0.8616 - precision: 0.5646 - recall: 0.8398 - auc: 0.9563 - val_loss: 0.2631 - val_accuracy: 0.8568 - val_precision: 0.4625 - val_recall: 0.5441 - val_auc: 0.8657\n",
      "Epoch 22/80\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.2174 - accuracy: 0.8592 - precision: 0.5315 - recall: 0.8307 - auc: 0.9626 - val_loss: 0.3127 - val_accuracy: 0.8349 - val_precision: 0.4286 - val_recall: 0.6176 - val_auc: 0.8697\n",
      "Epoch 23/80\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.1928 - accuracy: 0.8762 - precision: 0.6108 - recall: 0.8728 - auc: 0.9725 - val_loss: 0.3281 - val_accuracy: 0.8130 - val_precision: 0.3728 - val_recall: 0.6250 - val_auc: 0.8531\n",
      "Epoch 24/80\n",
      "49/49 [==============================] - 5s 97ms/step - loss: 0.1832 - accuracy: 0.8748 - precision: 0.6417 - recall: 0.8874 - auc: 0.9754 - val_loss: 0.3109 - val_accuracy: 0.8024 - val_precision: 0.4000 - val_recall: 0.6765 - val_auc: 0.8684\n",
      "Epoch 25/80\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.1881 - accuracy: 0.8821 - precision: 0.6112 - recall: 0.8847 - auc: 0.9727 - val_loss: 0.3294 - val_accuracy: 0.8282 - val_precision: 0.4074 - val_recall: 0.6471 - val_auc: 0.8615\n",
      "Epoch 26/80\n",
      "49/49 [==============================] - 5s 97ms/step - loss: 0.1829 - accuracy: 0.8944 - precision: 0.5915 - recall: 0.8680 - auc: 0.9738 - val_loss: 0.3418 - val_accuracy: 0.8011 - val_precision: 0.3829 - val_recall: 0.6250 - val_auc: 0.8345\n",
      "Epoch 27/80\n",
      "49/49 [==============================] - 5s 97ms/step - loss: 0.1922 - accuracy: 0.8852 - precision: 0.6127 - recall: 0.8740 - auc: 0.9708 - val_loss: 0.3477 - val_accuracy: 0.8296 - val_precision: 0.3756 - val_recall: 0.5882 - val_auc: 0.8314\n",
      "Epoch 28/80\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 0.2015 - accuracy: 0.8766 - precision: 0.5940 - recall: 0.8504 - auc: 0.9712 - val_loss: 0.2903 - val_accuracy: 0.8342 - val_precision: 0.4541 - val_recall: 0.6176 - val_auc: 0.8471\n",
      "Epoch 29/80\n",
      "49/49 [==============================] - 4s 92ms/step - loss: 0.1890 - accuracy: 0.8957 - precision: 0.6621 - recall: 0.8929 - auc: 0.9734 - val_loss: 0.3596 - val_accuracy: 0.8395 - val_precision: 0.4022 - val_recall: 0.5441 - val_auc: 0.8352\n",
      "Epoch 30/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.1833 - accuracy: 0.8954 - precision: 0.6196 - recall: 0.8923 - auc: 0.9736 - val_loss: 0.3551 - val_accuracy: 0.8117 - val_precision: 0.3877 - val_recall: 0.6471 - val_auc: 0.8504\n",
      "Epoch 31/80\n",
      "49/49 [==============================] - 4s 87ms/step - loss: 0.1640 - accuracy: 0.8972 - precision: 0.6454 - recall: 0.8984 - auc: 0.9791 - val_loss: 0.4023 - val_accuracy: 0.7772 - val_precision: 0.3100 - val_recall: 0.6838 - val_auc: 0.8436\n",
      "Epoch 32/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.1598 - accuracy: 0.8953 - precision: 0.6338 - recall: 0.9084 - auc: 0.9800 - val_loss: 0.3156 - val_accuracy: 0.8349 - val_precision: 0.3846 - val_recall: 0.5515 - val_auc: 0.8503\n",
      "Epoch 33/80\n",
      "49/49 [==============================] - 4s 87ms/step - loss: 0.1522 - accuracy: 0.9053 - precision: 0.6232 - recall: 0.8814 - auc: 0.9809 - val_loss: 0.3326 - val_accuracy: 0.8077 - val_precision: 0.3930 - val_recall: 0.6618 - val_auc: 0.8527\n",
      "Epoch 34/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.1744 - accuracy: 0.8923 - precision: 0.6514 - recall: 0.8870 - auc: 0.9757 - val_loss: 0.3319 - val_accuracy: 0.8263 - val_precision: 0.3807 - val_recall: 0.5515 - val_auc: 0.8245\n",
      "Epoch 35/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.1762 - accuracy: 0.8877 - precision: 0.6339 - recall: 0.8871 - auc: 0.9760 - val_loss: 0.3224 - val_accuracy: 0.8621 - val_precision: 0.4605 - val_recall: 0.5147 - val_auc: 0.8286\n",
      "Epoch 36/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.1393 - accuracy: 0.9171 - precision: 0.7049 - recall: 0.9134 - auc: 0.9841 - val_loss: 0.3132 - val_accuracy: 0.8508 - val_precision: 0.4518 - val_recall: 0.5515 - val_auc: 0.8390\n",
      "Epoch 37/80\n",
      "49/49 [==============================] - 5s 93ms/step - loss: 0.1422 - accuracy: 0.9090 - precision: 0.6884 - recall: 0.9031 - auc: 0.9842 - val_loss: 0.3223 - val_accuracy: 0.8216 - val_precision: 0.4322 - val_recall: 0.6324 - val_auc: 0.8536\n",
      "Epoch 38/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.1532 - accuracy: 0.9025 - precision: 0.6455 - recall: 0.8861 - auc: 0.9813 - val_loss: 0.2960 - val_accuracy: 0.8369 - val_precision: 0.4404 - val_recall: 0.6250 - val_auc: 0.8589\n",
      "\n",
      "8 16 256\n",
      "Training model 1\n",
      "Epoch 1/80\n",
      "49/49 [==============================] - 6s 96ms/step - loss: 0.7273 - accuracy: 0.4384 - precision: 0.1279 - recall: 0.1413 - auc: 0.5535 - val_loss: 0.8742 - val_accuracy: 0.1797 - val_precision: 0.1446 - val_recall: 0.8603 - val_auc: 0.7535\n",
      "Epoch 2/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.5178 - accuracy: 0.5816 - precision: 0.2691 - recall: 0.3542 - auc: 0.7596 - val_loss: 1.0960 - val_accuracy: 0.2606 - val_precision: 0.1483 - val_recall: 0.9191 - val_auc: 0.8134\n",
      "Epoch 3/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.4889 - accuracy: 0.6556 - precision: 0.3135 - recall: 0.4947 - auc: 0.8157 - val_loss: 0.3767 - val_accuracy: 0.6127 - val_precision: 0.3013 - val_recall: 0.6691 - val_auc: 0.8519\n",
      "Epoch 4/80\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.4031 - accuracy: 0.7357 - precision: 0.3936 - recall: 0.5777 - auc: 0.8729 - val_loss: 0.2421 - val_accuracy: 0.8501 - val_precision: 0.4595 - val_recall: 0.3750 - val_auc: 0.8542\n",
      "Epoch 5/80\n",
      "49/49 [==============================] - 5s 94ms/step - loss: 0.3914 - accuracy: 0.7519 - precision: 0.4064 - recall: 0.5882 - auc: 0.8777 - val_loss: 0.2531 - val_accuracy: 0.8674 - val_precision: 0.4717 - val_recall: 0.3676 - val_auc: 0.8570\n",
      "Epoch 6/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.3436 - accuracy: 0.7911 - precision: 0.4194 - recall: 0.6855 - auc: 0.9093 - val_loss: 0.2823 - val_accuracy: 0.8117 - val_precision: 0.4152 - val_recall: 0.5221 - val_auc: 0.8501\n",
      "Epoch 7/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.3417 - accuracy: 0.7603 - precision: 0.4375 - recall: 0.7200 - auc: 0.9131 - val_loss: 0.2558 - val_accuracy: 0.8269 - val_precision: 0.4104 - val_recall: 0.4044 - val_auc: 0.8412\n",
      "Epoch 8/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.3432 - accuracy: 0.7632 - precision: 0.4289 - recall: 0.6889 - auc: 0.9088 - val_loss: 0.3125 - val_accuracy: 0.8793 - val_precision: 0.4842 - val_recall: 0.3382 - val_auc: 0.8164\n",
      "Epoch 9/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.3118 - accuracy: 0.8154 - precision: 0.4862 - recall: 0.7331 - auc: 0.9281 - val_loss: 0.2700 - val_accuracy: 0.8932 - val_precision: 0.5165 - val_recall: 0.3456 - val_auc: 0.8499\n",
      "Epoch 10/80\n",
      "49/49 [==============================] - 5s 93ms/step - loss: 0.2871 - accuracy: 0.8149 - precision: 0.4622 - recall: 0.7585 - auc: 0.9343 - val_loss: 0.2787 - val_accuracy: 0.8992 - val_precision: 0.4717 - val_recall: 0.3676 - val_auc: 0.8478\n",
      "Epoch 11/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2733 - accuracy: 0.8338 - precision: 0.4776 - recall: 0.7423 - auc: 0.9429 - val_loss: 0.2984 - val_accuracy: 0.8501 - val_precision: 0.4198 - val_recall: 0.5000 - val_auc: 0.8465\n",
      "Epoch 12/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.2594 - accuracy: 0.8386 - precision: 0.5040 - recall: 0.7562 - auc: 0.9452 - val_loss: 0.2835 - val_accuracy: 0.8667 - val_precision: 0.4583 - val_recall: 0.4853 - val_auc: 0.8458\n",
      "Epoch 13/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2616 - accuracy: 0.8428 - precision: 0.5088 - recall: 0.7997 - auc: 0.9478 - val_loss: 0.3143 - val_accuracy: 0.8243 - val_precision: 0.3838 - val_recall: 0.5221 - val_auc: 0.8370\n",
      "Epoch 14/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2414 - accuracy: 0.8378 - precision: 0.5212 - recall: 0.8030 - auc: 0.9538 - val_loss: 0.2866 - val_accuracy: 0.8859 - val_precision: 0.5351 - val_recall: 0.4485 - val_auc: 0.8435\n",
      "Epoch 15/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2344 - accuracy: 0.8612 - precision: 0.5492 - recall: 0.8271 - auc: 0.9572 - val_loss: 0.3257 - val_accuracy: 0.8700 - val_precision: 0.4638 - val_recall: 0.4706 - val_auc: 0.8262\n",
      "Epoch 16/80\n",
      "49/49 [==============================] - 4s 87ms/step - loss: 0.2611 - accuracy: 0.8404 - precision: 0.5120 - recall: 0.8349 - auc: 0.9487 - val_loss: 0.3264 - val_accuracy: 0.8899 - val_precision: 0.4786 - val_recall: 0.4118 - val_auc: 0.8219\n",
      "Epoch 17/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2271 - accuracy: 0.8584 - precision: 0.5683 - recall: 0.8516 - auc: 0.9614 - val_loss: 0.3280 - val_accuracy: 0.8780 - val_precision: 0.4508 - val_recall: 0.4044 - val_auc: 0.8234\n",
      "Epoch 18/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2317 - accuracy: 0.8510 - precision: 0.5314 - recall: 0.8303 - auc: 0.9590 - val_loss: 0.2740 - val_accuracy: 0.8820 - val_precision: 0.5273 - val_recall: 0.4265 - val_auc: 0.8453\n",
      "Epoch 19/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2206 - accuracy: 0.8657 - precision: 0.5518 - recall: 0.8604 - auc: 0.9619 - val_loss: 0.3457 - val_accuracy: 0.8939 - val_precision: 0.4898 - val_recall: 0.3529 - val_auc: 0.8059\n",
      "Epoch 20/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2466 - accuracy: 0.8641 - precision: 0.5800 - recall: 0.8122 - auc: 0.9559 - val_loss: 0.3291 - val_accuracy: 0.8674 - val_precision: 0.4344 - val_recall: 0.3897 - val_auc: 0.7990\n",
      "Epoch 21/80\n",
      "49/49 [==============================] - 4s 87ms/step - loss: 0.2283 - accuracy: 0.8677 - precision: 0.5767 - recall: 0.8082 - auc: 0.9607 - val_loss: 0.3114 - val_accuracy: 0.8893 - val_precision: 0.5146 - val_recall: 0.3897 - val_auc: 0.8243\n",
      "Epoch 22/80\n",
      "49/49 [==============================] - 4s 87ms/step - loss: 0.2141 - accuracy: 0.8736 - precision: 0.5969 - recall: 0.8330 - auc: 0.9650 - val_loss: 0.3088 - val_accuracy: 0.8793 - val_precision: 0.4427 - val_recall: 0.4265 - val_auc: 0.8413\n",
      "Epoch 23/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2013 - accuracy: 0.8834 - precision: 0.6056 - recall: 0.8487 - auc: 0.9684 - val_loss: 0.3262 - val_accuracy: 0.8939 - val_precision: 0.5000 - val_recall: 0.3529 - val_auc: 0.8212\n",
      "Epoch 24/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2025 - accuracy: 0.8769 - precision: 0.5752 - recall: 0.8322 - auc: 0.9670 - val_loss: 0.3070 - val_accuracy: 0.8707 - val_precision: 0.4667 - val_recall: 0.4118 - val_auc: 0.8314\n",
      "Epoch 25/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.1888 - accuracy: 0.8842 - precision: 0.6374 - recall: 0.8735 - auc: 0.9725 - val_loss: 0.3633 - val_accuracy: 0.8979 - val_precision: 0.5222 - val_recall: 0.3456 - val_auc: 0.8082\n",
      "\n",
      "8 16 256\n",
      "Training model 2\n",
      "Epoch 1/80\n",
      "49/49 [==============================] - 5s 95ms/step - loss: 0.6505 - accuracy: 0.4603 - precision: 0.1095 - recall: 0.0914 - auc: 0.5270 - val_loss: 1.1754 - val_accuracy: 0.0902 - val_precision: 0.1053 - val_recall: 0.9706 - val_auc: 0.7324\n",
      "Epoch 2/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.5700 - accuracy: 0.5198 - precision: 0.2618 - recall: 0.3663 - auc: 0.7285 - val_loss: 0.9902 - val_accuracy: 0.1618 - val_precision: 0.1432 - val_recall: 0.9191 - val_auc: 0.7926\n",
      "Epoch 3/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.4902 - accuracy: 0.6253 - precision: 0.2942 - recall: 0.4179 - auc: 0.7988 - val_loss: 0.3655 - val_accuracy: 0.6121 - val_precision: 0.2727 - val_recall: 0.5515 - val_auc: 0.7988\n",
      "Epoch 4/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.4649 - accuracy: 0.6791 - precision: 0.3407 - recall: 0.4378 - auc: 0.8193 - val_loss: 0.3208 - val_accuracy: 0.7109 - val_precision: 0.3318 - val_recall: 0.5441 - val_auc: 0.8316\n",
      "Epoch 5/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.4397 - accuracy: 0.6995 - precision: 0.3418 - recall: 0.5608 - auc: 0.8491 - val_loss: 0.2422 - val_accuracy: 0.8647 - val_precision: 0.4737 - val_recall: 0.2647 - val_auc: 0.8436\n",
      "Epoch 6/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.4183 - accuracy: 0.7468 - precision: 0.4002 - recall: 0.5634 - auc: 0.8705 - val_loss: 0.2501 - val_accuracy: 0.8939 - val_precision: 0.5195 - val_recall: 0.2941 - val_auc: 0.8595\n",
      "Epoch 7/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.3560 - accuracy: 0.7706 - precision: 0.4273 - recall: 0.6974 - auc: 0.9019 - val_loss: 0.2558 - val_accuracy: 0.8634 - val_precision: 0.4505 - val_recall: 0.3676 - val_auc: 0.8606\n",
      "Epoch 8/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.3579 - accuracy: 0.7645 - precision: 0.3984 - recall: 0.6607 - auc: 0.8976 - val_loss: 0.2628 - val_accuracy: 0.8581 - val_precision: 0.4661 - val_recall: 0.4044 - val_auc: 0.8579\n",
      "Epoch 9/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.3220 - accuracy: 0.7779 - precision: 0.4377 - recall: 0.7245 - auc: 0.9196 - val_loss: 0.2604 - val_accuracy: 0.8826 - val_precision: 0.5082 - val_recall: 0.4559 - val_auc: 0.8704\n",
      "Epoch 10/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.3446 - accuracy: 0.7855 - precision: 0.4740 - recall: 0.7463 - auc: 0.9179 - val_loss: 0.2740 - val_accuracy: 0.8256 - val_precision: 0.4171 - val_recall: 0.5368 - val_auc: 0.8673\n",
      "Epoch 11/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.3036 - accuracy: 0.7933 - precision: 0.4522 - recall: 0.7458 - auc: 0.9305 - val_loss: 0.2674 - val_accuracy: 0.8820 - val_precision: 0.5000 - val_recall: 0.3750 - val_auc: 0.8468\n",
      "Epoch 12/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2801 - accuracy: 0.8366 - precision: 0.5090 - recall: 0.7846 - auc: 0.9387 - val_loss: 0.2780 - val_accuracy: 0.8826 - val_precision: 0.5658 - val_recall: 0.3162 - val_auc: 0.8346\n",
      "Epoch 13/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2762 - accuracy: 0.8226 - precision: 0.5206 - recall: 0.7624 - auc: 0.9423 - val_loss: 0.2689 - val_accuracy: 0.9032 - val_precision: 0.6133 - val_recall: 0.3382 - val_auc: 0.8515\n",
      "Epoch 14/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2639 - accuracy: 0.8346 - precision: 0.5260 - recall: 0.7777 - auc: 0.9480 - val_loss: 0.3063 - val_accuracy: 0.8004 - val_precision: 0.3956 - val_recall: 0.6544 - val_auc: 0.8655\n",
      "Epoch 15/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2644 - accuracy: 0.8290 - precision: 0.5107 - recall: 0.7845 - auc: 0.9477 - val_loss: 0.2512 - val_accuracy: 0.8813 - val_precision: 0.4955 - val_recall: 0.4044 - val_auc: 0.8583\n",
      "Epoch 16/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2485 - accuracy: 0.8393 - precision: 0.5439 - recall: 0.8272 - auc: 0.9537 - val_loss: 0.3052 - val_accuracy: 0.8574 - val_precision: 0.4532 - val_recall: 0.4632 - val_auc: 0.8307\n",
      "Epoch 17/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2229 - accuracy: 0.8582 - precision: 0.5503 - recall: 0.8436 - auc: 0.9614 - val_loss: 0.2737 - val_accuracy: 0.8488 - val_precision: 0.4500 - val_recall: 0.4632 - val_auc: 0.8438\n",
      "Epoch 18/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2328 - accuracy: 0.8482 - precision: 0.5484 - recall: 0.8436 - auc: 0.9576 - val_loss: 0.2646 - val_accuracy: 0.8946 - val_precision: 0.5238 - val_recall: 0.3235 - val_auc: 0.8649\n",
      "Epoch 19/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2239 - accuracy: 0.8574 - precision: 0.5813 - recall: 0.8358 - auc: 0.9626 - val_loss: 0.3200 - val_accuracy: 0.8833 - val_precision: 0.4956 - val_recall: 0.4118 - val_auc: 0.8408\n",
      "Epoch 20/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2259 - accuracy: 0.8603 - precision: 0.5458 - recall: 0.8209 - auc: 0.9587 - val_loss: 0.2856 - val_accuracy: 0.8912 - val_precision: 0.5333 - val_recall: 0.4706 - val_auc: 0.8430\n",
      "Epoch 21/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2101 - accuracy: 0.8723 - precision: 0.5685 - recall: 0.8457 - auc: 0.9672 - val_loss: 0.3604 - val_accuracy: 0.8302 - val_precision: 0.3618 - val_recall: 0.5294 - val_auc: 0.8276\n",
      "Epoch 22/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2368 - accuracy: 0.8519 - precision: 0.5391 - recall: 0.8258 - auc: 0.9591 - val_loss: 0.3093 - val_accuracy: 0.8912 - val_precision: 0.4917 - val_recall: 0.4338 - val_auc: 0.8271\n",
      "Epoch 23/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2068 - accuracy: 0.8643 - precision: 0.5900 - recall: 0.8835 - auc: 0.9687 - val_loss: 0.3238 - val_accuracy: 0.8926 - val_precision: 0.5426 - val_recall: 0.3750 - val_auc: 0.8245\n",
      "Epoch 24/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.1946 - accuracy: 0.8827 - precision: 0.5883 - recall: 0.8293 - auc: 0.9710 - val_loss: 0.3493 - val_accuracy: 0.8800 - val_precision: 0.5652 - val_recall: 0.3824 - val_auc: 0.7753\n",
      "Epoch 25/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2054 - accuracy: 0.8761 - precision: 0.5805 - recall: 0.8404 - auc: 0.9665 - val_loss: 0.2844 - val_accuracy: 0.8800 - val_precision: 0.5000 - val_recall: 0.4191 - val_auc: 0.8416\n",
      "Epoch 26/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.1903 - accuracy: 0.8783 - precision: 0.6231 - recall: 0.8390 - auc: 0.9715 - val_loss: 0.2886 - val_accuracy: 0.8906 - val_precision: 0.5413 - val_recall: 0.4338 - val_auc: 0.8404\n",
      "Epoch 27/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2130 - accuracy: 0.8617 - precision: 0.5874 - recall: 0.8396 - auc: 0.9646 - val_loss: 0.3015 - val_accuracy: 0.8574 - val_precision: 0.4500 - val_recall: 0.5294 - val_auc: 0.8411\n",
      "Epoch 28/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.1821 - accuracy: 0.8789 - precision: 0.6088 - recall: 0.8763 - auc: 0.9742 - val_loss: 0.3039 - val_accuracy: 0.8740 - val_precision: 0.4803 - val_recall: 0.4485 - val_auc: 0.8474\n",
      "Epoch 29/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.1805 - accuracy: 0.8815 - precision: 0.6263 - recall: 0.8598 - auc: 0.9751 - val_loss: 0.3307 - val_accuracy: 0.8773 - val_precision: 0.4320 - val_recall: 0.3971 - val_auc: 0.8197\n",
      "\n",
      "8 16 128\n",
      "Training model 3\n",
      "Epoch 1/80\n",
      "49/49 [==============================] - 6s 100ms/step - loss: 0.6822 - accuracy: 0.3944 - precision: 0.0852 - recall: 0.0572 - auc: 0.5048 - val_loss: 0.5152 - val_accuracy: 0.0942 - val_precision: 0.1693 - val_recall: 0.3162 - val_auc: 0.6274\n",
      "Epoch 2/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.5851 - accuracy: 0.4090 - precision: 0.2689 - recall: 0.2088 - auc: 0.6698 - val_loss: 0.7180 - val_accuracy: 0.2029 - val_precision: 0.1607 - val_recall: 0.7868 - val_auc: 0.7700\n",
      "Epoch 3/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.5117 - accuracy: 0.5532 - precision: 0.3244 - recall: 0.4201 - auc: 0.7811 - val_loss: 0.5167 - val_accuracy: 0.4012 - val_precision: 0.2289 - val_recall: 0.7794 - val_auc: 0.8230\n",
      "Epoch 4/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.4652 - accuracy: 0.6490 - precision: 0.3045 - recall: 0.4234 - auc: 0.8038 - val_loss: 0.4959 - val_accuracy: 0.4629 - val_precision: 0.2411 - val_recall: 0.7500 - val_auc: 0.8303\n",
      "Epoch 5/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.3940 - accuracy: 0.6961 - precision: 0.3672 - recall: 0.5767 - auc: 0.8512 - val_loss: 0.2555 - val_accuracy: 0.8110 - val_precision: 0.4029 - val_recall: 0.4118 - val_auc: 0.8510\n",
      "Epoch 6/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.3789 - accuracy: 0.7609 - precision: 0.4049 - recall: 0.5771 - auc: 0.8827 - val_loss: 0.2752 - val_accuracy: 0.7513 - val_precision: 0.3990 - val_recall: 0.5809 - val_auc: 0.8651\n",
      "Epoch 7/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.3606 - accuracy: 0.7319 - precision: 0.4234 - recall: 0.6260 - auc: 0.8886 - val_loss: 0.2595 - val_accuracy: 0.8017 - val_precision: 0.4152 - val_recall: 0.5221 - val_auc: 0.8671\n",
      "Epoch 8/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.3421 - accuracy: 0.7739 - precision: 0.4269 - recall: 0.6802 - auc: 0.9084 - val_loss: 0.2455 - val_accuracy: 0.8767 - val_precision: 0.4312 - val_recall: 0.3456 - val_auc: 0.8540\n",
      "Epoch 9/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.3399 - accuracy: 0.7724 - precision: 0.4720 - recall: 0.6989 - auc: 0.9049 - val_loss: 0.2548 - val_accuracy: 0.9012 - val_precision: 0.5238 - val_recall: 0.3235 - val_auc: 0.8535\n",
      "Epoch 10/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.3118 - accuracy: 0.8046 - precision: 0.4898 - recall: 0.7352 - auc: 0.9262 - val_loss: 0.2447 - val_accuracy: 0.8680 - val_precision: 0.4865 - val_recall: 0.3971 - val_auc: 0.8573\n",
      "Epoch 11/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2826 - accuracy: 0.8040 - precision: 0.4782 - recall: 0.6979 - auc: 0.9312 - val_loss: 0.2610 - val_accuracy: 0.8966 - val_precision: 0.4600 - val_recall: 0.3382 - val_auc: 0.8513\n",
      "Epoch 12/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.3247 - accuracy: 0.7886 - precision: 0.5201 - recall: 0.7426 - auc: 0.9162 - val_loss: 0.2563 - val_accuracy: 0.9065 - val_precision: 0.5368 - val_recall: 0.3750 - val_auc: 0.8676\n",
      "Epoch 13/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2776 - accuracy: 0.8345 - precision: 0.5311 - recall: 0.7788 - auc: 0.9429 - val_loss: 0.2663 - val_accuracy: 0.8886 - val_precision: 0.5098 - val_recall: 0.3824 - val_auc: 0.8426\n",
      "Epoch 14/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2581 - accuracy: 0.8479 - precision: 0.5527 - recall: 0.7481 - auc: 0.9422 - val_loss: 0.2676 - val_accuracy: 0.8992 - val_precision: 0.4949 - val_recall: 0.3603 - val_auc: 0.8569\n",
      "Epoch 15/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2449 - accuracy: 0.8465 - precision: 0.5657 - recall: 0.7994 - auc: 0.9519 - val_loss: 0.2696 - val_accuracy: 0.8740 - val_precision: 0.4755 - val_recall: 0.5000 - val_auc: 0.8629\n",
      "Epoch 16/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2347 - accuracy: 0.8564 - precision: 0.5450 - recall: 0.8272 - auc: 0.9569 - val_loss: 0.2623 - val_accuracy: 0.8893 - val_precision: 0.5225 - val_recall: 0.4265 - val_auc: 0.8644\n",
      "Epoch 17/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2258 - accuracy: 0.8590 - precision: 0.5643 - recall: 0.8312 - auc: 0.9577 - val_loss: 0.3226 - val_accuracy: 0.8395 - val_precision: 0.3793 - val_recall: 0.4853 - val_auc: 0.8368\n",
      "Epoch 18/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2332 - accuracy: 0.8539 - precision: 0.5519 - recall: 0.8188 - auc: 0.9529 - val_loss: 0.3253 - val_accuracy: 0.8727 - val_precision: 0.4380 - val_recall: 0.4412 - val_auc: 0.8345\n",
      "Epoch 19/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.1940 - accuracy: 0.8728 - precision: 0.5957 - recall: 0.8558 - auc: 0.9705 - val_loss: 0.2948 - val_accuracy: 0.8932 - val_precision: 0.4516 - val_recall: 0.3088 - val_auc: 0.8332\n",
      "Epoch 20/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2278 - accuracy: 0.8651 - precision: 0.5876 - recall: 0.8274 - auc: 0.9604 - val_loss: 0.3334 - val_accuracy: 0.8541 - val_precision: 0.3775 - val_recall: 0.4191 - val_auc: 0.8160\n",
      "Epoch 21/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2046 - accuracy: 0.8572 - precision: 0.5739 - recall: 0.8453 - auc: 0.9671 - val_loss: 0.2867 - val_accuracy: 0.8899 - val_precision: 0.5126 - val_recall: 0.4485 - val_auc: 0.8372\n",
      "Epoch 22/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.1960 - accuracy: 0.8693 - precision: 0.6065 - recall: 0.8365 - auc: 0.9693 - val_loss: 0.2721 - val_accuracy: 0.8926 - val_precision: 0.5413 - val_recall: 0.4338 - val_auc: 0.8317\n",
      "Epoch 23/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.1867 - accuracy: 0.8956 - precision: 0.6378 - recall: 0.8850 - auc: 0.9701 - val_loss: 0.2637 - val_accuracy: 0.9078 - val_precision: 0.5909 - val_recall: 0.3824 - val_auc: 0.8528\n",
      "Epoch 24/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2118 - accuracy: 0.8683 - precision: 0.6170 - recall: 0.8542 - auc: 0.9655 - val_loss: 0.3112 - val_accuracy: 0.9164 - val_precision: 0.6061 - val_recall: 0.2941 - val_auc: 0.8059\n",
      "Epoch 25/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.1659 - accuracy: 0.8959 - precision: 0.6457 - recall: 0.8778 - auc: 0.9741 - val_loss: 0.2994 - val_accuracy: 0.8999 - val_precision: 0.5246 - val_recall: 0.4706 - val_auc: 0.8303\n",
      "Epoch 26/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.1997 - accuracy: 0.8902 - precision: 0.6141 - recall: 0.8419 - auc: 0.9679 - val_loss: 0.2702 - val_accuracy: 0.8952 - val_precision: 0.4846 - val_recall: 0.4632 - val_auc: 0.8609\n",
      "Epoch 27/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.1723 - accuracy: 0.8944 - precision: 0.6313 - recall: 0.8755 - auc: 0.9750 - val_loss: 0.2982 - val_accuracy: 0.8999 - val_precision: 0.5699 - val_recall: 0.3897 - val_auc: 0.8313\n",
      "Epoch 28/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.1760 - accuracy: 0.8985 - precision: 0.6381 - recall: 0.8706 - auc: 0.9742 - val_loss: 0.3053 - val_accuracy: 0.8939 - val_precision: 0.4831 - val_recall: 0.4191 - val_auc: 0.8251\n",
      "Epoch 29/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.1783 - accuracy: 0.8878 - precision: 0.6292 - recall: 0.8895 - auc: 0.9710 - val_loss: 0.3036 - val_accuracy: 0.8826 - val_precision: 0.4800 - val_recall: 0.4412 - val_auc: 0.8343\n",
      "Epoch 30/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.1834 - accuracy: 0.8940 - precision: 0.6602 - recall: 0.8489 - auc: 0.9724 - val_loss: 0.2786 - val_accuracy: 0.8919 - val_precision: 0.5385 - val_recall: 0.4632 - val_auc: 0.8367\n",
      "Epoch 31/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.1840 - accuracy: 0.8940 - precision: 0.6777 - recall: 0.8516 - auc: 0.9705 - val_loss: 0.2982 - val_accuracy: 0.9032 - val_precision: 0.5200 - val_recall: 0.3824 - val_auc: 0.8381\n",
      "Epoch 32/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.1493 - accuracy: 0.9121 - precision: 0.6354 - recall: 0.8837 - auc: 0.9813 - val_loss: 0.2967 - val_accuracy: 0.8932 - val_precision: 0.4806 - val_recall: 0.4559 - val_auc: 0.8457\n",
      "\n",
      "8 16 128\n",
      "Training model 4\n",
      "Epoch 1/80\n",
      "49/49 [==============================] - 5s 95ms/step - loss: 0.7074 - accuracy: 0.3762 - precision: 0.1139 - recall: 0.0683 - auc: 0.4893 - val_loss: 0.3342 - val_accuracy: 0.3906 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5989\n",
      "Epoch 2/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.6454 - accuracy: 0.2844 - precision: 0.1450 - recall: 0.0695 - auc: 0.5525 - val_loss: 0.4340 - val_accuracy: 0.1870 - val_precision: 0.2512 - val_recall: 0.3824 - val_auc: 0.7592\n",
      "Epoch 3/80\n",
      "49/49 [==============================] - 5s 92ms/step - loss: 0.5561 - accuracy: 0.5026 - precision: 0.2497 - recall: 0.2199 - auc: 0.7042 - val_loss: 0.5433 - val_accuracy: 0.3276 - val_precision: 0.2163 - val_recall: 0.7794 - val_auc: 0.8174\n",
      "Epoch 4/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.5045 - accuracy: 0.5748 - precision: 0.3326 - recall: 0.4326 - auc: 0.7936 - val_loss: 0.4258 - val_accuracy: 0.5391 - val_precision: 0.2466 - val_recall: 0.6765 - val_auc: 0.8262\n",
      "Epoch 5/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.4854 - accuracy: 0.6360 - precision: 0.3419 - recall: 0.4774 - auc: 0.8181 - val_loss: 0.4503 - val_accuracy: 0.6127 - val_precision: 0.2500 - val_recall: 0.6838 - val_auc: 0.8354\n",
      "Epoch 6/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.4311 - accuracy: 0.6865 - precision: 0.3379 - recall: 0.5359 - auc: 0.8486 - val_loss: 0.4503 - val_accuracy: 0.6034 - val_precision: 0.2554 - val_recall: 0.6985 - val_auc: 0.8514\n",
      "Epoch 7/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.4132 - accuracy: 0.7146 - precision: 0.3823 - recall: 0.6672 - auc: 0.8776 - val_loss: 0.2768 - val_accuracy: 0.7354 - val_precision: 0.3818 - val_recall: 0.6176 - val_auc: 0.8638\n",
      "Epoch 8/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.3620 - accuracy: 0.7475 - precision: 0.4533 - recall: 0.6805 - auc: 0.9035 - val_loss: 0.2558 - val_accuracy: 0.7891 - val_precision: 0.4032 - val_recall: 0.5515 - val_auc: 0.8702\n",
      "Epoch 9/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.3246 - accuracy: 0.7839 - precision: 0.4554 - recall: 0.6711 - auc: 0.9145 - val_loss: 0.2791 - val_accuracy: 0.7938 - val_precision: 0.3850 - val_recall: 0.5662 - val_auc: 0.8586\n",
      "Epoch 10/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.3647 - accuracy: 0.7521 - precision: 0.4545 - recall: 0.7090 - auc: 0.9010 - val_loss: 0.2918 - val_accuracy: 0.8415 - val_precision: 0.3949 - val_recall: 0.5662 - val_auc: 0.8681\n",
      "Epoch 11/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.3298 - accuracy: 0.8066 - precision: 0.4765 - recall: 0.7543 - auc: 0.9212 - val_loss: 0.2896 - val_accuracy: 0.8103 - val_precision: 0.3781 - val_recall: 0.5588 - val_auc: 0.8535\n",
      "Epoch 12/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.3056 - accuracy: 0.8127 - precision: 0.4941 - recall: 0.7241 - auc: 0.9280 - val_loss: 0.3945 - val_accuracy: 0.7354 - val_precision: 0.2721 - val_recall: 0.5882 - val_auc: 0.8217\n",
      "Epoch 13/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.2782 - accuracy: 0.8199 - precision: 0.4902 - recall: 0.7546 - auc: 0.9382 - val_loss: 0.3048 - val_accuracy: 0.7898 - val_precision: 0.3671 - val_recall: 0.5588 - val_auc: 0.8527\n",
      "Epoch 14/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.3068 - accuracy: 0.8187 - precision: 0.5012 - recall: 0.7684 - auc: 0.9345 - val_loss: 0.2772 - val_accuracy: 0.8229 - val_precision: 0.4058 - val_recall: 0.6176 - val_auc: 0.8789\n",
      "Epoch 15/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.2741 - accuracy: 0.8209 - precision: 0.5090 - recall: 0.7709 - auc: 0.9408 - val_loss: 0.3848 - val_accuracy: 0.7513 - val_precision: 0.3356 - val_recall: 0.7353 - val_auc: 0.8652\n",
      "Epoch 16/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2714 - accuracy: 0.8069 - precision: 0.5145 - recall: 0.8368 - auc: 0.9412 - val_loss: 0.2784 - val_accuracy: 0.8534 - val_precision: 0.4204 - val_recall: 0.4853 - val_auc: 0.8643\n",
      "Epoch 17/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.2432 - accuracy: 0.8457 - precision: 0.5290 - recall: 0.8123 - auc: 0.9551 - val_loss: 0.2593 - val_accuracy: 0.8302 - val_precision: 0.4244 - val_recall: 0.5368 - val_auc: 0.8710\n",
      "Epoch 18/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.2579 - accuracy: 0.8390 - precision: 0.5320 - recall: 0.8060 - auc: 0.9491 - val_loss: 0.2927 - val_accuracy: 0.8276 - val_precision: 0.3855 - val_recall: 0.5074 - val_auc: 0.8517\n",
      "Epoch 19/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2245 - accuracy: 0.8567 - precision: 0.5605 - recall: 0.8388 - auc: 0.9613 - val_loss: 0.3281 - val_accuracy: 0.8143 - val_precision: 0.3460 - val_recall: 0.5368 - val_auc: 0.8562\n",
      "Epoch 20/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.2651 - accuracy: 0.8338 - precision: 0.5232 - recall: 0.8215 - auc: 0.9469 - val_loss: 0.2906 - val_accuracy: 0.8249 - val_precision: 0.4082 - val_recall: 0.5882 - val_auc: 0.8672\n",
      "Epoch 21/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2067 - accuracy: 0.8626 - precision: 0.5937 - recall: 0.8480 - auc: 0.9673 - val_loss: 0.2854 - val_accuracy: 0.8548 - val_precision: 0.4400 - val_recall: 0.4853 - val_auc: 0.8411\n",
      "Epoch 22/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.2242 - accuracy: 0.8534 - precision: 0.5819 - recall: 0.8427 - auc: 0.9626 - val_loss: 0.3429 - val_accuracy: 0.8097 - val_precision: 0.3392 - val_recall: 0.5662 - val_auc: 0.8420\n",
      "Epoch 23/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.2423 - accuracy: 0.8449 - precision: 0.5326 - recall: 0.7913 - auc: 0.9544 - val_loss: 0.2982 - val_accuracy: 0.8210 - val_precision: 0.3824 - val_recall: 0.5735 - val_auc: 0.8652\n",
      "Epoch 24/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.2185 - accuracy: 0.8648 - precision: 0.5869 - recall: 0.8485 - auc: 0.9617 - val_loss: 0.3400 - val_accuracy: 0.8037 - val_precision: 0.3504 - val_recall: 0.6029 - val_auc: 0.8668\n",
      "Epoch 25/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.1932 - accuracy: 0.8860 - precision: 0.5844 - recall: 0.8791 - auc: 0.9707 - val_loss: 0.3798 - val_accuracy: 0.7779 - val_precision: 0.3190 - val_recall: 0.6544 - val_auc: 0.8713\n",
      "Epoch 26/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.1932 - accuracy: 0.8830 - precision: 0.5920 - recall: 0.8760 - auc: 0.9715 - val_loss: 0.3728 - val_accuracy: 0.7958 - val_precision: 0.3108 - val_recall: 0.5735 - val_auc: 0.8325\n",
      "Epoch 27/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.1844 - accuracy: 0.8865 - precision: 0.6145 - recall: 0.8778 - auc: 0.9719 - val_loss: 0.3166 - val_accuracy: 0.8269 - val_precision: 0.3846 - val_recall: 0.6250 - val_auc: 0.8677\n",
      "Epoch 28/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.1773 - accuracy: 0.8986 - precision: 0.6639 - recall: 0.8887 - auc: 0.9739 - val_loss: 0.3893 - val_accuracy: 0.7812 - val_precision: 0.3207 - val_recall: 0.6838 - val_auc: 0.8579\n",
      "Epoch 29/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.1825 - accuracy: 0.8754 - precision: 0.5979 - recall: 0.8880 - auc: 0.9725 - val_loss: 0.3346 - val_accuracy: 0.8229 - val_precision: 0.3684 - val_recall: 0.6176 - val_auc: 0.8641\n",
      "Epoch 30/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2359 - accuracy: 0.8664 - precision: 0.6026 - recall: 0.8384 - auc: 0.9603 - val_loss: 0.3027 - val_accuracy: 0.8336 - val_precision: 0.3827 - val_recall: 0.5515 - val_auc: 0.8540\n",
      "Epoch 31/80\n",
      "49/49 [==============================] - 4s 89ms/step - loss: 0.2005 - accuracy: 0.8713 - precision: 0.5862 - recall: 0.8479 - auc: 0.9692 - val_loss: 0.2965 - val_accuracy: 0.8654 - val_precision: 0.4444 - val_recall: 0.4706 - val_auc: 0.8371\n",
      "Epoch 32/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.1634 - accuracy: 0.9038 - precision: 0.6568 - recall: 0.8750 - auc: 0.9782 - val_loss: 0.4441 - val_accuracy: 0.7653 - val_precision: 0.3179 - val_recall: 0.7059 - val_auc: 0.8670\n",
      "Epoch 33/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.1920 - accuracy: 0.8703 - precision: 0.5962 - recall: 0.8980 - auc: 0.9725 - val_loss: 0.3714 - val_accuracy: 0.7858 - val_precision: 0.3502 - val_recall: 0.6618 - val_auc: 0.8454\n",
      "Epoch 34/80\n",
      "49/49 [==============================] - 4s 90ms/step - loss: 0.1905 - accuracy: 0.8895 - precision: 0.6237 - recall: 0.8865 - auc: 0.9731 - val_loss: 0.3349 - val_accuracy: 0.7924 - val_precision: 0.3432 - val_recall: 0.5956 - val_auc: 0.8535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "M = 5\n",
    "models = [None] * M\n",
    "for m in range(M):\n",
    "    X, y, w = get_bootstrap_sample(X_train, y_train, w_train)\n",
    "    bias = calculate_bias(y)\n",
    "    r = np.random.randint(5)\n",
    "    models[m] = build_model(bias, r)\n",
    "    sgd = tf.keras.optimizers.SGD(lr=0.05, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "    models[m].compile(loss='binary_crossentropy', optimizer=sgd, metrics=get_metrics())\n",
    "    print(f'Training model {m}')\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=20, mode='max', restore_best_weights=True)\n",
    "    models[m].fit(\n",
    "      X, \n",
    "      y, \n",
    "      batch_size=128,\n",
    "      epochs=80, \n",
    "      shuffle=True,\n",
    "      verbose=1,\n",
    "      sample_weight=w,\n",
    "      validation_data=(X_val, y_val),\n",
    "      callbacks=[early_stopping]\n",
    "    )\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = np.zeros((M, X_test.shape[0]))\n",
    "for m in range(M):\n",
    "    m_pred = models[m].predict(X_test, batch_size=1)\n",
    "    votes[m] = m_pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = votes.sum(axis=0)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2732 - accuracy: 0.8614 - precision: 0.4072 - recall: 0.4463 - auc: 0.8279\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.2570 - accuracy: 0.8595 - precision: 0.4615 - recall: 0.3051 - auc: 0.8094\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.2707 - accuracy: 0.8827 - precision: 0.4522 - recall: 0.4011 - auc: 0.8247\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.9032 - precision: 0.5701 - recall: 0.3446 - auc: 0.8325\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.2869 - accuracy: 0.8059 - precision: 0.3557 - recall: 0.5085 - auc: 0.8194\n"
     ]
    }
   ],
   "source": [
    "for m in range(M):\n",
    "    models[m].evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_2 = models[4].predict(X_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96      2023\n",
      "         1.0       0.53      0.39      0.45       177\n",
      "\n",
      "    accuracy                           0.92      2200\n",
      "   macro avg       0.74      0.68      0.70      2200\n",
      "weighted avg       0.91      0.92      0.92      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [1 if (p > 0.5) else 0 for p in preds]\n",
    "y_pred = np.asarray(y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score:  0.5870271625563724\n",
      "Precision:  0.5529377420824789\n",
      "Recall:  0.6553977747398799\n"
     ]
    }
   ],
   "source": [
    "f_score, precision, recall = evaluate(harmonix_beats, preds_2, ids_test, True)\n",
    "\n",
    "print(\"F-score: \", f_score)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(M):\n",
    "    models[m].save(os.path.join(ROOT, 'models', f'model_{m}.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(ROOT, 'data', '06_Results', 'harmonix_voting.npz'), preds=preds, ids=ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
