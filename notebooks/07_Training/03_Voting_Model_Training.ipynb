{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT = '/content/drive/MyDrive/fyp/collabs/'\n",
    "else:\n",
    "    ROOT = os.path.join(os.getcwd(), '..', '..') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Colab libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    !pip install pickle5\n",
    "    import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load custom modules"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install git+https://github.com/kingsleyzissou/nnssa.git@0.1.1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install mir_eval peakutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnssa.constants import *\n",
    "from nnssa.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TensorFlow modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics():\n",
    "    return [\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.15),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('COLAB_TPU_ADDR' in os.environ.keys()):\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "    tf.config.experimental_connect_to_host(resolver.master())\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress bars!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Sub_Divisions</th>\n",
       "      <th>Binary_Labels</th>\n",
       "      <th>Weighted_Labels</th>\n",
       "      <th>Weights</th>\n",
       "      <th>IDS</th>\n",
       "      <th>Beat_times</th>\n",
       "      <th>Labels</th>\n",
       "      <th>BPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_12step</td>\n",
       "      <td>bars/harmonix/0001_12step.npy</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0001_12step, 0001_12step, 0001_12step, 0001_1...</td>\n",
       "      <td>[0.0, 0.5309729999999999, 1.0619459999999998, ...</td>\n",
       "      <td>[0.0, 8.495567999999999, 25.486704, 42.4753280...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003_6foot7foot</td>\n",
       "      <td>bars/harmonix/0003_6foot7foot.npy</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0003_6foot7foot, 0003_6foot7foot, 0003_6foot7...</td>\n",
       "      <td>[2.857108, 3.571394, 4.28568, 4.99996600000000...</td>\n",
       "      <td>[2.857108, 8.571396, 31.428548, 37.14283599999...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004_abc</td>\n",
       "      <td>bars/harmonix/0004_abc.npy</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0004_abc, 0004_abc, 0004_abc, 0004_abc, 0004_...</td>\n",
       "      <td>[2.666656, 3.238084, 3.952369, 4.597529, 5.242...</td>\n",
       "      <td>[2.666656, 28.300542999999998, 58.263180000000...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006_aint2proud2beg</td>\n",
       "      <td>bars/harmonix/0006_aint2proud2beg.npy</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0006_aint2proud2beg, 0006_aint2proud2beg, 000...</td>\n",
       "      <td>[0.0, 0.572203, 1.144406, 1.716609, 2.288812, ...</td>\n",
       "      <td>[0.0, 27.4652, 45.203726, 63.518522999999995, ...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008_america</td>\n",
       "      <td>bars/harmonix/0008_america.npy</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0008_america, 0008_america, 0008_america, 000...</td>\n",
       "      <td>[3.871208, 4.359011, 4.846814, 5.338616, 5.830...</td>\n",
       "      <td>[3.871208, 10.56504, 33.217138, 56.85190400000...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  File                          Sub_Divisions  \\\n",
       "0          0001_12step          bars/harmonix/0001_12step.npy   \n",
       "1      0003_6foot7foot      bars/harmonix/0003_6foot7foot.npy   \n",
       "2             0004_abc             bars/harmonix/0004_abc.npy   \n",
       "3  0006_aint2proud2beg  bars/harmonix/0006_aint2proud2beg.npy   \n",
       "4         0008_america         bars/harmonix/0008_america.npy   \n",
       "\n",
       "                                       Binary_Labels  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     Weighted_Labels  \\\n",
       "0  [1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                             Weights  \\\n",
       "0  [3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, ...   \n",
       "1  [3.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2  [3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [3.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [3.0, 0.5, 1.0, 0.5, 3.0, 0.5, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                                 IDS  \\\n",
       "0  [0001_12step, 0001_12step, 0001_12step, 0001_1...   \n",
       "1  [0003_6foot7foot, 0003_6foot7foot, 0003_6foot7...   \n",
       "2  [0004_abc, 0004_abc, 0004_abc, 0004_abc, 0004_...   \n",
       "3  [0006_aint2proud2beg, 0006_aint2proud2beg, 000...   \n",
       "4  [0008_america, 0008_america, 0008_america, 000...   \n",
       "\n",
       "                                          Beat_times  \\\n",
       "0  [0.0, 0.5309729999999999, 1.0619459999999998, ...   \n",
       "1  [2.857108, 3.571394, 4.28568, 4.99996600000000...   \n",
       "2  [2.666656, 3.238084, 3.952369, 4.597529, 5.242...   \n",
       "3  [0.0, 0.572203, 1.144406, 1.716609, 2.288812, ...   \n",
       "4  [3.871208, 4.359011, 4.846814, 5.338616, 5.830...   \n",
       "\n",
       "                                              Labels  BPM  \n",
       "0  [0.0, 8.495567999999999, 25.486704, 42.4753280...  113  \n",
       "1  [2.857108, 8.571396, 31.428548, 37.14283599999...   84  \n",
       "2  [2.666656, 28.300542999999998, 58.263180000000...   94  \n",
       "3  [0.0, 27.4652, 45.203726, 63.518522999999995, ...  105  \n",
       "4  [3.871208, 10.56504, 33.217138, 56.85190400000...  136  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if COLAB:\n",
    "    harmonix_beats = pickle.load(open(os.path.join(ROOT, SUB_DIVS_DIR, 'bars', 'harmonix.p'), 'rb'))\n",
    "else:\n",
    "    harmonix_beats = pd.read_pickle(os.path.join(ROOT, SUB_DIVS_DIR, 'bars', 'harmonix.p'))\n",
    "harmonix_beats = harmonix_beats.head(100)\n",
    "harmonix_beats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Mel Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_np(file):\n",
    "    return np.load(os.path.join(ROOT, SUB_DIVS_DIR, file), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 166.79it/s]\n"
     ]
    }
   ],
   "source": [
    "harmonix_beats['Sub_Divisions'] = harmonix_beats['Sub_Divisions'].progress_map(load_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# harmonix_beats['Oversamples'] = harmonix_beats['Oversamples'].progress_map(load_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = harmonix_beats.copy()\n",
    "y = harmonix_beats['Binary_Labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, _, _ = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, _, _ = train_test_split(X_train, X_train['Binary_Labels'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.concatenate(X_train['Over_Labels'].values)\n",
    "y_train = np.concatenate(X_train['Binary_Labels'].values)\n",
    "y_test = np.concatenate(X_test['Binary_Labels'].values)\n",
    "y_val = np.concatenate(X_val['Binary_Labels'].values)\n",
    "\n",
    "ids_test = np.concatenate(X_test['IDS'].values)\n",
    "\n",
    "# w_train = np.concatenate(X_train['Over_Weights'].values)\n",
    "w_train = np.concatenate(X_train['Weights'].values)\n",
    "w_test = np.concatenate(X_test['Weights'].values)\n",
    "w_val = np.concatenate(X_val['Weights'].values)\n",
    "\n",
    "# X_train = np.concatenate(X_train['Oversamples'].values)\n",
    "X_train = np.concatenate(X_train['Sub_Divisions'].values)\n",
    "X_test = np.concatenate(X_test['Sub_Divisions'].values)\n",
    "X_val = np.concatenate(X_val['Sub_Divisions'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 566, 0.0: 5654})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Initial Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bias(y):\n",
    "    count = np.bincount(y.astype('int64'))\n",
    "    neg, pos = count[0], count[1]\n",
    "    total = neg + pos\n",
    "    return np.log([pos/neg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(initial_bias, rand):\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "    bias_initializer = tf.keras.initializers.Constant(initial_bias)\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "    neurons = [[32, 64, 256], [64, 128, 256], [32, 64, 512], [8, 16, 128], [64, 128, 256],]\n",
    "    first_neuron, second_neuron, third_neuron = neurons[rand]\n",
    "    print(first_neuron, second_neuron, third_neuron)\n",
    "    return Sequential([\n",
    "        Input(shape=(N_MELS, 4, 33)),\n",
    "        Conv2D(first_neuron, 8, activation='relu', kernel_initializer=initializer, padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(5, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Conv2D(second_neuron, 6, activation='relu', padding=\"same\", kernel_initializer=initializer),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Flatten(),\n",
    "        Dense(third_neuron, activation='sigmoid'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid', bias_initializer=bias_initializer)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIY Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_sample(X_train, y_train, w_train):\n",
    "    n = X_train.shape[0]\n",
    "    samples = np.random.choice(n, size=n)\n",
    "    return X_train[samples, :, :, :], y_train[samples], w_train[samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 64 256\n",
      "Training model 0\n",
      "Epoch 1/80\n",
      "49/49 [==============================] - 11s 202ms/step - loss: 0.6646 - accuracy: 0.4239 - precision: 0.1330 - recall: 0.1361 - auc: 0.5635 - val_loss: 0.4195 - val_accuracy: 0.4450 - val_precision: 0.2258 - val_recall: 0.4118 - val_auc: 0.7269\n",
      "Epoch 2/80\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 0.5250 - accuracy: 0.6371 - precision: 0.2954 - recall: 0.4062 - auc: 0.7837 - val_loss: 0.6495 - val_accuracy: 0.4337 - val_precision: 0.1877 - val_recall: 0.7868 - val_auc: 0.8172\n",
      "Epoch 3/80\n",
      "49/49 [==============================] - 9s 180ms/step - loss: 0.3731 - accuracy: 0.7384 - precision: 0.4124 - recall: 0.6159 - auc: 0.8866 - val_loss: 0.3810 - val_accuracy: 0.6664 - val_precision: 0.3116 - val_recall: 0.6691 - val_auc: 0.8636\n",
      "Epoch 4/80\n",
      "49/49 [==============================] - 9s 182ms/step - loss: 0.3285 - accuracy: 0.7847 - precision: 0.4712 - recall: 0.7036 - auc: 0.9179 - val_loss: 0.2988 - val_accuracy: 0.7858 - val_precision: 0.3951 - val_recall: 0.5956 - val_auc: 0.8594\n",
      "Epoch 5/80\n",
      "49/49 [==============================] - 9s 176ms/step - loss: 0.2653 - accuracy: 0.8301 - precision: 0.5643 - recall: 0.7880 - auc: 0.9475 - val_loss: 0.3088 - val_accuracy: 0.8196 - val_precision: 0.4078 - val_recall: 0.6176 - val_auc: 0.8709\n",
      "Epoch 6/80\n",
      "49/49 [==============================] - 9s 174ms/step - loss: 0.2181 - accuracy: 0.8592 - precision: 0.5734 - recall: 0.8371 - auc: 0.9621 - val_loss: 0.2983 - val_accuracy: 0.8568 - val_precision: 0.4459 - val_recall: 0.4853 - val_auc: 0.8421\n",
      "Epoch 7/80\n",
      "49/49 [==============================] - 9s 175ms/step - loss: 0.2022 - accuracy: 0.8667 - precision: 0.5928 - recall: 0.8596 - auc: 0.9689 - val_loss: 0.3655 - val_accuracy: 0.8475 - val_precision: 0.4226 - val_recall: 0.5221 - val_auc: 0.8258\n",
      "Epoch 8/80\n",
      "49/49 [==============================] - 9s 181ms/step - loss: 0.1913 - accuracy: 0.8763 - precision: 0.6273 - recall: 0.8728 - auc: 0.9724 - val_loss: 0.3198 - val_accuracy: 0.8674 - val_precision: 0.4874 - val_recall: 0.4265 - val_auc: 0.8264\n",
      "Epoch 9/80\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 0.1748 - accuracy: 0.8940 - precision: 0.6524 - recall: 0.8555 - auc: 0.9769 - val_loss: 0.3464 - val_accuracy: 0.8733 - val_precision: 0.4730 - val_recall: 0.5147 - val_auc: 0.8369\n",
      "Epoch 10/80\n",
      "49/49 [==============================] - 9s 178ms/step - loss: 0.1675 - accuracy: 0.8995 - precision: 0.6449 - recall: 0.8673 - auc: 0.9782 - val_loss: 0.3560 - val_accuracy: 0.8939 - val_precision: 0.5000 - val_recall: 0.4044 - val_auc: 0.8075\n",
      "Epoch 11/80\n",
      "49/49 [==============================] - 9s 176ms/step - loss: 0.1372 - accuracy: 0.9235 - precision: 0.7187 - recall: 0.9091 - auc: 0.9856 - val_loss: 0.3731 - val_accuracy: 0.8906 - val_precision: 0.5246 - val_recall: 0.4706 - val_auc: 0.8095\n",
      "Epoch 12/80\n",
      "49/49 [==============================] - 9s 183ms/step - loss: 0.1167 - accuracy: 0.9287 - precision: 0.7270 - recall: 0.9183 - auc: 0.9884 - val_loss: 0.3952 - val_accuracy: 0.9125 - val_precision: 0.5930 - val_recall: 0.3750 - val_auc: 0.7890\n",
      "Epoch 13/80\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 0.1724 - accuracy: 0.9120 - precision: 0.6642 - recall: 0.8649 - auc: 0.9786 - val_loss: 0.3476 - val_accuracy: 0.8680 - val_precision: 0.4786 - val_recall: 0.4926 - val_auc: 0.8137\n",
      "Epoch 14/80\n",
      "49/49 [==============================] - 8s 153ms/step - loss: 0.1250 - accuracy: 0.9165 - precision: 0.6919 - recall: 0.9074 - auc: 0.9869 - val_loss: 0.4192 - val_accuracy: 0.8594 - val_precision: 0.4241 - val_recall: 0.4926 - val_auc: 0.8073\n",
      "Epoch 15/80\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.1106 - accuracy: 0.9270 - precision: 0.7335 - recall: 0.9286 - auc: 0.9903 - val_loss: 0.3773 - val_accuracy: 0.9012 - val_precision: 0.5596 - val_recall: 0.4485 - val_auc: 0.8112\n",
      "Epoch 16/80\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.1098 - accuracy: 0.9368 - precision: 0.7734 - recall: 0.9331 - auc: 0.9912 - val_loss: 0.4667 - val_accuracy: 0.8952 - val_precision: 0.4865 - val_recall: 0.3971 - val_auc: 0.7661\n",
      "Epoch 17/80\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.1049 - accuracy: 0.9373 - precision: 0.7664 - recall: 0.9441 - auc: 0.9905 - val_loss: 0.4152 - val_accuracy: 0.8853 - val_precision: 0.5000 - val_recall: 0.4853 - val_auc: 0.8010\n",
      "Epoch 18/80\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.1002 - accuracy: 0.9416 - precision: 0.7771 - recall: 0.9526 - auc: 0.9908 - val_loss: 0.3794 - val_accuracy: 0.8952 - val_precision: 0.5038 - val_recall: 0.4853 - val_auc: 0.8317\n",
      "Epoch 19/80\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0957 - accuracy: 0.9433 - precision: 0.7879 - recall: 0.9375 - auc: 0.9921 - val_loss: 0.4439 - val_accuracy: 0.8926 - val_precision: 0.5100 - val_recall: 0.3750 - val_auc: 0.7797\n",
      "Epoch 20/80\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.0756 - accuracy: 0.9539 - precision: 0.8353 - recall: 0.9411 - auc: 0.9950 - val_loss: 0.3957 - val_accuracy: 0.8866 - val_precision: 0.5413 - val_recall: 0.4338 - val_auc: 0.7875\n",
      "Epoch 21/80\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0905 - accuracy: 0.9463 - precision: 0.8005 - recall: 0.9528 - auc: 0.9933 - val_loss: 0.4570 - val_accuracy: 0.8972 - val_precision: 0.5565 - val_recall: 0.4706 - val_auc: 0.7888\n",
      "Epoch 22/80\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0802 - accuracy: 0.9518 - precision: 0.7709 - recall: 0.9431 - auc: 0.9950 - val_loss: 0.4565 - val_accuracy: 0.8959 - val_precision: 0.5524 - val_recall: 0.4265 - val_auc: 0.7807\n",
      "Epoch 23/80\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0628 - accuracy: 0.9611 - precision: 0.8469 - recall: 0.9506 - auc: 0.9964 - val_loss: 0.4630 - val_accuracy: 0.9012 - val_precision: 0.6067 - val_recall: 0.3971 - val_auc: 0.7809\n",
      "Epoch 24/80\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0816 - accuracy: 0.9555 - precision: 0.8126 - recall: 0.9575 - auc: 0.9929 - val_loss: 0.5095 - val_accuracy: 0.9012 - val_precision: 0.6154 - val_recall: 0.3529 - val_auc: 0.7645\n",
      "Epoch 25/80\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0714 - accuracy: 0.9580 - precision: 0.8207 - recall: 0.9499 - auc: 0.9959 - val_loss: 0.4828 - val_accuracy: 0.8999 - val_precision: 0.5979 - val_recall: 0.4265 - val_auc: 0.7785\n",
      "\n",
      "32 64 256\n",
      "Training model 1\n",
      "Epoch 1/80\n",
      "49/49 [==============================] - 9s 162ms/step - loss: 0.6548 - accuracy: 0.4523 - precision: 0.1511 - recall: 0.1646 - auc: 0.5882 - val_loss: 1.2232 - val_accuracy: 0.1021 - val_precision: 0.1061 - val_recall: 0.9632 - val_auc: 0.8031\n",
      "Epoch 2/80\n",
      "49/49 [==============================] - 9s 189ms/step - loss: 0.4604 - accuracy: 0.6635 - precision: 0.3139 - recall: 0.4669 - auc: 0.8118 - val_loss: 0.9152 - val_accuracy: 0.3263 - val_precision: 0.1572 - val_recall: 0.9118 - val_auc: 0.8370\n",
      "Epoch 3/80\n",
      "49/49 [==============================] - 9s 184ms/step - loss: 0.4014 - accuracy: 0.7332 - precision: 0.3815 - recall: 0.6230 - auc: 0.8791 - val_loss: 0.3579 - val_accuracy: 0.6996 - val_precision: 0.3312 - val_recall: 0.7574 - val_auc: 0.8625\n",
      "Epoch 4/80\n",
      "49/49 [==============================] - 9s 182ms/step - loss: 0.3278 - accuracy: 0.8062 - precision: 0.4500 - recall: 0.7057 - auc: 0.9168 - val_loss: 0.4488 - val_accuracy: 0.7221 - val_precision: 0.3136 - val_recall: 0.7794 - val_auc: 0.8671\n",
      "Epoch 5/80\n",
      "49/49 [==============================] - 9s 178ms/step - loss: 0.2708 - accuracy: 0.8226 - precision: 0.5188 - recall: 0.8026 - auc: 0.9434 - val_loss: 0.2718 - val_accuracy: 0.8667 - val_precision: 0.4748 - val_recall: 0.4853 - val_auc: 0.8562\n",
      "Epoch 6/80\n",
      "49/49 [==============================] - 9s 180ms/step - loss: 0.2661 - accuracy: 0.8408 - precision: 0.5282 - recall: 0.7755 - auc: 0.9441 - val_loss: 0.2962 - val_accuracy: 0.8150 - val_precision: 0.4250 - val_recall: 0.6250 - val_auc: 0.8739\n",
      "Epoch 7/80\n",
      "49/49 [==============================] - 8s 172ms/step - loss: 0.2067 - accuracy: 0.8628 - precision: 0.5881 - recall: 0.8437 - auc: 0.9667 - val_loss: 0.3637 - val_accuracy: 0.8468 - val_precision: 0.4326 - val_recall: 0.5662 - val_auc: 0.8532\n",
      "Epoch 8/80\n",
      "49/49 [==============================] - 9s 181ms/step - loss: 0.1978 - accuracy: 0.8723 - precision: 0.5910 - recall: 0.8681 - auc: 0.9698 - val_loss: 0.2991 - val_accuracy: 0.8296 - val_precision: 0.4076 - val_recall: 0.6324 - val_auc: 0.8740\n",
      "Epoch 9/80\n",
      "49/49 [==============================] - 9s 177ms/step - loss: 0.1895 - accuracy: 0.8823 - precision: 0.6142 - recall: 0.8676 - auc: 0.9711 - val_loss: 0.3270 - val_accuracy: 0.8541 - val_precision: 0.4176 - val_recall: 0.5588 - val_auc: 0.8709\n",
      "Epoch 10/80\n",
      "49/49 [==============================] - 9s 185ms/step - loss: 0.1658 - accuracy: 0.8930 - precision: 0.5979 - recall: 0.8471 - auc: 0.9768 - val_loss: 0.3208 - val_accuracy: 0.8581 - val_precision: 0.4270 - val_recall: 0.5809 - val_auc: 0.8724\n",
      "Epoch 11/80\n",
      "49/49 [==============================] - 9s 180ms/step - loss: 0.1535 - accuracy: 0.8971 - precision: 0.6660 - recall: 0.8906 - auc: 0.9806 - val_loss: 0.3121 - val_accuracy: 0.8760 - val_precision: 0.4759 - val_recall: 0.5074 - val_auc: 0.8590\n",
      "Epoch 12/80\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 0.1616 - accuracy: 0.9025 - precision: 0.6614 - recall: 0.8870 - auc: 0.9804 - val_loss: 0.3380 - val_accuracy: 0.8422 - val_precision: 0.4382 - val_recall: 0.5735 - val_auc: 0.8417\n",
      "Epoch 13/80\n",
      "49/49 [==============================] - 8s 164ms/step - loss: 0.1489 - accuracy: 0.9049 - precision: 0.6822 - recall: 0.8984 - auc: 0.9832 - val_loss: 0.3696 - val_accuracy: 0.8786 - val_precision: 0.4771 - val_recall: 0.5368 - val_auc: 0.8220\n",
      "Epoch 14/80\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.1417 - accuracy: 0.9136 - precision: 0.7146 - recall: 0.9027 - auc: 0.9832 - val_loss: 0.3430 - val_accuracy: 0.8979 - val_precision: 0.5826 - val_recall: 0.4926 - val_auc: 0.8273\n",
      "Epoch 15/80\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.1125 - accuracy: 0.9346 - precision: 0.7622 - recall: 0.9074 - auc: 0.9902 - val_loss: 0.3788 - val_accuracy: 0.9005 - val_precision: 0.5234 - val_recall: 0.4926 - val_auc: 0.8322\n",
      "Epoch 16/80\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0967 - accuracy: 0.9413 - precision: 0.7679 - recall: 0.9274 - auc: 0.9928 - val_loss: 0.4294 - val_accuracy: 0.8786 - val_precision: 0.4610 - val_recall: 0.4779 - val_auc: 0.7978\n",
      "Epoch 17/80\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0961 - accuracy: 0.9254 - precision: 0.7239 - recall: 0.9145 - auc: 0.9904 - val_loss: 0.4473 - val_accuracy: 0.8813 - val_precision: 0.4522 - val_recall: 0.5221 - val_auc: 0.8172\n",
      "Epoch 18/80\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.1312 - accuracy: 0.9266 - precision: 0.7021 - recall: 0.9192 - auc: 0.9868 - val_loss: 0.3524 - val_accuracy: 0.8912 - val_precision: 0.4931 - val_recall: 0.5221 - val_auc: 0.8544\n",
      "Epoch 19/80\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0919 - accuracy: 0.9299 - precision: 0.7556 - recall: 0.9279 - auc: 0.9928 - val_loss: 0.3787 - val_accuracy: 0.8773 - val_precision: 0.4935 - val_recall: 0.5588 - val_auc: 0.8456\n",
      "Epoch 20/80\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0896 - accuracy: 0.9410 - precision: 0.7578 - recall: 0.9372 - auc: 0.9928 - val_loss: 0.3783 - val_accuracy: 0.9019 - val_precision: 0.5906 - val_recall: 0.5515 - val_auc: 0.8272\n",
      "Epoch 21/80\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0898 - accuracy: 0.9433 - precision: 0.7729 - recall: 0.9244 - auc: 0.9924 - val_loss: 0.4656 - val_accuracy: 0.8793 - val_precision: 0.4532 - val_recall: 0.4632 - val_auc: 0.7857\n",
      "Epoch 22/80\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0886 - accuracy: 0.9434 - precision: 0.7596 - recall: 0.9448 - auc: 0.9929 - val_loss: 0.4231 - val_accuracy: 0.8992 - val_precision: 0.4844 - val_recall: 0.4559 - val_auc: 0.8218\n",
      "Epoch 23/80\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0735 - accuracy: 0.9529 - precision: 0.8178 - recall: 0.9566 - auc: 0.9952 - val_loss: 0.4597 - val_accuracy: 0.8767 - val_precision: 0.4797 - val_recall: 0.5221 - val_auc: 0.7968\n",
      "Epoch 24/80\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0757 - accuracy: 0.9468 - precision: 0.7898 - recall: 0.9581 - auc: 0.9955 - val_loss: 0.4620 - val_accuracy: 0.8946 - val_precision: 0.4806 - val_recall: 0.4559 - val_auc: 0.7916\n",
      "Epoch 25/80\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0900 - accuracy: 0.9467 - precision: 0.7749 - recall: 0.9297 - auc: 0.9906 - val_loss: 0.4333 - val_accuracy: 0.8800 - val_precision: 0.4641 - val_recall: 0.5221 - val_auc: 0.8142\n",
      "Epoch 26/80\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0682 - accuracy: 0.9524 - precision: 0.8047 - recall: 0.9614 - auc: 0.9951 - val_loss: 0.4388 - val_accuracy: 0.8767 - val_precision: 0.4509 - val_recall: 0.5735 - val_auc: 0.8264\n",
      "Epoch 27/80\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0925 - accuracy: 0.9397 - precision: 0.7955 - recall: 0.9489 - auc: 0.9937 - val_loss: 0.4084 - val_accuracy: 0.8886 - val_precision: 0.5175 - val_recall: 0.5441 - val_auc: 0.8108\n",
      "Epoch 28/80\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0583 - accuracy: 0.9629 - precision: 0.8370 - recall: 0.9477 - auc: 0.9972 - val_loss: 0.4700 - val_accuracy: 0.8853 - val_precision: 0.4337 - val_recall: 0.5294 - val_auc: 0.8207\n",
      "\n",
      "32 64 256\n",
      "Training model 2\n",
      "Epoch 1/80\n",
      "49/49 [==============================] - 7s 119ms/step - loss: 0.6639 - accuracy: 0.4220 - precision: 0.1361 - recall: 0.1306 - auc: 0.5643 - val_loss: 1.5597 - val_accuracy: 0.0902 - val_precision: 0.0958 - val_recall: 1.0000 - val_auc: 0.7632\n",
      "Epoch 2/80\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.5488 - accuracy: 0.5418 - precision: 0.2558 - recall: 0.4065 - auc: 0.7487 - val_loss: 0.9839 - val_accuracy: 0.2440 - val_precision: 0.1465 - val_recall: 0.9265 - val_auc: 0.8025\n",
      "Epoch 3/80\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.4399 - accuracy: 0.6770 - precision: 0.3676 - recall: 0.5854 - auc: 0.8519 - val_loss: 0.4044 - val_accuracy: 0.6472 - val_precision: 0.2803 - val_recall: 0.7647 - val_auc: 0.8533\n",
      "Epoch 4/80\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.3517 - accuracy: 0.7681 - precision: 0.4281 - recall: 0.6715 - auc: 0.9055 - val_loss: 0.2569 - val_accuracy: 0.8077 - val_precision: 0.4133 - val_recall: 0.4559 - val_auc: 0.8541\n",
      "Epoch 5/80\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.3182 - accuracy: 0.8054 - precision: 0.4892 - recall: 0.7399 - auc: 0.9236 - val_loss: 0.3189 - val_accuracy: 0.7135 - val_precision: 0.3415 - val_recall: 0.7206 - val_auc: 0.8718\n",
      "Epoch 6/80\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.2604 - accuracy: 0.8083 - precision: 0.5207 - recall: 0.7738 - auc: 0.9458 - val_loss: 0.2663 - val_accuracy: 0.8342 - val_precision: 0.4438 - val_recall: 0.5515 - val_auc: 0.8744\n",
      "Epoch 7/80\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.2341 - accuracy: 0.8501 - precision: 0.5901 - recall: 0.8248 - auc: 0.9605 - val_loss: 0.2653 - val_accuracy: 0.8879 - val_precision: 0.5385 - val_recall: 0.4118 - val_auc: 0.8602\n",
      "Epoch 8/80\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.2387 - accuracy: 0.8594 - precision: 0.5588 - recall: 0.7707 - auc: 0.9581 - val_loss: 0.3488 - val_accuracy: 0.8448 - val_precision: 0.4294 - val_recall: 0.5368 - val_auc: 0.8254\n",
      "Epoch 9/80\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.2014 - accuracy: 0.8716 - precision: 0.5687 - recall: 0.8539 - auc: 0.9675 - val_loss: 0.3412 - val_accuracy: 0.8395 - val_precision: 0.3990 - val_recall: 0.6103 - val_auc: 0.8700\n",
      "Epoch 10/80\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.1861 - accuracy: 0.8753 - precision: 0.5940 - recall: 0.8796 - auc: 0.9730 - val_loss: 0.2883 - val_accuracy: 0.9032 - val_precision: 0.5673 - val_recall: 0.4338 - val_auc: 0.8407\n",
      "Epoch 11/80\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.1704 - accuracy: 0.9029 - precision: 0.6397 - recall: 0.8722 - auc: 0.9774 - val_loss: 0.3250 - val_accuracy: 0.8707 - val_precision: 0.4522 - val_recall: 0.5221 - val_auc: 0.8366\n",
      "Epoch 12/80\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.1487 - accuracy: 0.9180 - precision: 0.7074 - recall: 0.9132 - auc: 0.9839 - val_loss: 0.3166 - val_accuracy: 0.8873 - val_precision: 0.5000 - val_recall: 0.5221 - val_auc: 0.8560\n",
      "Epoch 13/80\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.1592 - accuracy: 0.9128 - precision: 0.7024 - recall: 0.9132 - auc: 0.9790 - val_loss: 0.3152 - val_accuracy: 0.8733 - val_precision: 0.4713 - val_recall: 0.5441 - val_auc: 0.8536\n",
      "Epoch 14/80\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.1258 - accuracy: 0.9212 - precision: 0.7084 - recall: 0.9106 - auc: 0.9874 - val_loss: 0.3813 - val_accuracy: 0.8747 - val_precision: 0.4512 - val_recall: 0.5441 - val_auc: 0.8230\n",
      "Epoch 15/80\n",
      "49/49 [==============================] - 7s 143ms/step - loss: 0.1279 - accuracy: 0.9239 - precision: 0.7321 - recall: 0.9117 - auc: 0.9860 - val_loss: 0.3692 - val_accuracy: 0.8853 - val_precision: 0.4557 - val_recall: 0.5294 - val_auc: 0.8396\n",
      "Epoch 16/80\n",
      "49/49 [==============================] - 9s 180ms/step - loss: 0.1049 - accuracy: 0.9308 - precision: 0.7419 - recall: 0.9238 - auc: 0.9908 - val_loss: 0.3965 - val_accuracy: 0.8528 - val_precision: 0.4216 - val_recall: 0.5735 - val_auc: 0.8393\n",
      "Epoch 17/80\n",
      "49/49 [==============================] - 9s 186ms/step - loss: 0.1108 - accuracy: 0.9370 - precision: 0.7260 - recall: 0.9228 - auc: 0.9895 - val_loss: 0.3569 - val_accuracy: 0.8674 - val_precision: 0.4641 - val_recall: 0.5221 - val_auc: 0.8311\n",
      "Epoch 18/80\n",
      "49/49 [==============================] - 9s 181ms/step - loss: 0.0971 - accuracy: 0.9392 - precision: 0.7505 - recall: 0.9337 - auc: 0.9915 - val_loss: 0.3571 - val_accuracy: 0.8720 - val_precision: 0.4967 - val_recall: 0.5515 - val_auc: 0.8202\n",
      "Epoch 19/80\n",
      "49/49 [==============================] - 9s 182ms/step - loss: 0.1139 - accuracy: 0.9279 - precision: 0.7088 - recall: 0.9183 - auc: 0.9877 - val_loss: 0.3989 - val_accuracy: 0.8780 - val_precision: 0.5109 - val_recall: 0.5147 - val_auc: 0.8005\n",
      "Epoch 20/80\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 0.1089 - accuracy: 0.9356 - precision: 0.7480 - recall: 0.9383 - auc: 0.9905 - val_loss: 0.3556 - val_accuracy: 0.8899 - val_precision: 0.5333 - val_recall: 0.4706 - val_auc: 0.8269\n",
      "Epoch 21/80\n",
      "49/49 [==============================] - 9s 178ms/step - loss: 0.1013 - accuracy: 0.9395 - precision: 0.7832 - recall: 0.9304 - auc: 0.9905 - val_loss: 0.3463 - val_accuracy: 0.8879 - val_precision: 0.5615 - val_recall: 0.5368 - val_auc: 0.8295\n",
      "Epoch 22/80\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 0.1009 - accuracy: 0.9416 - precision: 0.7601 - recall: 0.8989 - auc: 0.9911 - val_loss: 0.3623 - val_accuracy: 0.9131 - val_precision: 0.6186 - val_recall: 0.4412 - val_auc: 0.8230\n",
      "Epoch 23/80\n",
      "49/49 [==============================] - 9s 182ms/step - loss: 0.0820 - accuracy: 0.9533 - precision: 0.7996 - recall: 0.9467 - auc: 0.9940 - val_loss: 0.3780 - val_accuracy: 0.8952 - val_precision: 0.5290 - val_recall: 0.5368 - val_auc: 0.8327\n",
      "Epoch 24/80\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 0.0755 - accuracy: 0.9507 - precision: 0.8008 - recall: 0.9550 - auc: 0.9948 - val_loss: 0.4661 - val_accuracy: 0.8687 - val_precision: 0.4329 - val_recall: 0.5221 - val_auc: 0.7935\n",
      "Epoch 25/80\n",
      "49/49 [==============================] - 9s 183ms/step - loss: 0.0888 - accuracy: 0.9439 - precision: 0.7736 - recall: 0.9447 - auc: 0.9925 - val_loss: 0.3812 - val_accuracy: 0.9105 - val_precision: 0.5413 - val_recall: 0.4338 - val_auc: 0.8097\n",
      "Epoch 26/80\n",
      "49/49 [==============================] - 9s 181ms/step - loss: 0.0667 - accuracy: 0.9594 - precision: 0.8392 - recall: 0.9453 - auc: 0.9941 - val_loss: 0.4224 - val_accuracy: 0.8946 - val_precision: 0.5566 - val_recall: 0.4338 - val_auc: 0.7850\n",
      "\n",
      "8 16 128\n",
      "Training model 3\n",
      "Epoch 1/80\n",
      "49/49 [==============================] - 9s 154ms/step - loss: 0.6586 - accuracy: 0.3885 - precision: 0.1525 - recall: 0.1019 - auc: 0.5547 - val_loss: 0.5713 - val_accuracy: 0.1419 - val_precision: 0.1590 - val_recall: 0.5809 - val_auc: 0.6810\n",
      "Epoch 2/80\n",
      "49/49 [==============================] - 7s 143ms/step - loss: 0.5341 - accuracy: 0.5322 - precision: 0.2941 - recall: 0.3101 - auc: 0.7285 - val_loss: 0.5939 - val_accuracy: 0.2905 - val_precision: 0.1785 - val_recall: 0.7794 - val_auc: 0.7896\n",
      "Epoch 3/80\n",
      "49/49 [==============================] - 7s 141ms/step - loss: 0.5109 - accuracy: 0.6004 - precision: 0.3087 - recall: 0.3958 - auc: 0.7726 - val_loss: 0.6738 - val_accuracy: 0.3674 - val_precision: 0.1794 - val_recall: 0.8309 - val_auc: 0.8205\n",
      "Epoch 4/80\n",
      "49/49 [==============================] - 7s 141ms/step - loss: 0.4225 - accuracy: 0.6829 - precision: 0.3820 - recall: 0.6000 - auc: 0.8603 - val_loss: 0.2801 - val_accuracy: 0.7049 - val_precision: 0.3500 - val_recall: 0.4632 - val_auc: 0.8397\n",
      "Epoch 5/80\n",
      "49/49 [==============================] - 7s 142ms/step - loss: 0.3849 - accuracy: 0.7318 - precision: 0.3512 - recall: 0.4996 - auc: 0.8730 - val_loss: 0.2701 - val_accuracy: 0.8004 - val_precision: 0.3859 - val_recall: 0.5221 - val_auc: 0.8624\n",
      "Epoch 6/80\n",
      "49/49 [==============================] - 6s 112ms/step - loss: 0.3614 - accuracy: 0.7483 - precision: 0.3817 - recall: 0.6204 - auc: 0.8922 - val_loss: 0.2427 - val_accuracy: 0.8720 - val_precision: 0.4609 - val_recall: 0.3897 - val_auc: 0.8678\n",
      "Epoch 7/80\n",
      "49/49 [==============================] - 5s 93ms/step - loss: 0.3537 - accuracy: 0.7694 - precision: 0.4576 - recall: 0.6722 - auc: 0.9017 - val_loss: 0.2286 - val_accuracy: 0.8846 - val_precision: 0.4904 - val_recall: 0.3750 - val_auc: 0.8845\n",
      "Epoch 8/80\n",
      "49/49 [==============================] - 5s 93ms/step - loss: 0.3021 - accuracy: 0.8064 - precision: 0.4792 - recall: 0.7354 - auc: 0.9264 - val_loss: 0.2451 - val_accuracy: 0.8926 - val_precision: 0.4516 - val_recall: 0.3088 - val_auc: 0.8705\n",
      "Epoch 9/80\n",
      "49/49 [==============================] - 5s 93ms/step - loss: 0.3006 - accuracy: 0.8118 - precision: 0.5010 - recall: 0.7022 - auc: 0.9276 - val_loss: 0.3012 - val_accuracy: 0.8316 - val_precision: 0.3941 - val_recall: 0.4926 - val_auc: 0.8462\n",
      "Epoch 10/80\n",
      "49/49 [==============================] - 5s 93ms/step - loss: 0.2930 - accuracy: 0.7906 - precision: 0.4829 - recall: 0.7812 - auc: 0.9362 - val_loss: 0.2950 - val_accuracy: 0.9065 - val_precision: 0.6750 - val_recall: 0.1985 - val_auc: 0.8368\n",
      "Epoch 11/80\n",
      "49/49 [==============================] - 5s 94ms/step - loss: 0.2794 - accuracy: 0.8244 - precision: 0.5214 - recall: 0.7580 - auc: 0.9385 - val_loss: 0.2774 - val_accuracy: 0.8641 - val_precision: 0.4483 - val_recall: 0.3824 - val_auc: 0.8365\n",
      "Epoch 12/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.2635 - accuracy: 0.8242 - precision: 0.5168 - recall: 0.7711 - auc: 0.9431 - val_loss: 0.2938 - val_accuracy: 0.8501 - val_precision: 0.4497 - val_recall: 0.5588 - val_auc: 0.8657\n",
      "Epoch 13/80\n",
      "49/49 [==============================] - 5s 93ms/step - loss: 0.2527 - accuracy: 0.8341 - precision: 0.5554 - recall: 0.7943 - auc: 0.9536 - val_loss: 0.2621 - val_accuracy: 0.8568 - val_precision: 0.4474 - val_recall: 0.5000 - val_auc: 0.8680\n",
      "Epoch 14/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.2107 - accuracy: 0.8581 - precision: 0.5610 - recall: 0.8185 - auc: 0.9636 - val_loss: 0.2423 - val_accuracy: 0.8859 - val_precision: 0.4758 - val_recall: 0.4338 - val_auc: 0.8796\n",
      "Epoch 15/80\n",
      "49/49 [==============================] - 5s 93ms/step - loss: 0.2135 - accuracy: 0.8648 - precision: 0.5788 - recall: 0.8498 - auc: 0.9627 - val_loss: 0.2728 - val_accuracy: 0.8786 - val_precision: 0.4497 - val_recall: 0.4926 - val_auc: 0.8667\n",
      "Epoch 16/80\n",
      "49/49 [==============================] - 5s 93ms/step - loss: 0.2144 - accuracy: 0.8681 - precision: 0.5676 - recall: 0.8447 - auc: 0.9598 - val_loss: 0.3191 - val_accuracy: 0.8349 - val_precision: 0.3763 - val_recall: 0.5368 - val_auc: 0.8399\n",
      "Epoch 17/80\n",
      "49/49 [==============================] - 5s 93ms/step - loss: 0.2233 - accuracy: 0.8590 - precision: 0.5841 - recall: 0.8394 - auc: 0.9599 - val_loss: 0.2792 - val_accuracy: 0.8813 - val_precision: 0.5392 - val_recall: 0.4044 - val_auc: 0.8351\n",
      "Epoch 18/80\n",
      "49/49 [==============================] - 5s 94ms/step - loss: 0.2184 - accuracy: 0.8704 - precision: 0.6259 - recall: 0.8495 - auc: 0.9638 - val_loss: 0.2804 - val_accuracy: 0.8952 - val_precision: 0.5057 - val_recall: 0.3235 - val_auc: 0.8563\n",
      "Epoch 19/80\n",
      "49/49 [==============================] - 5s 92ms/step - loss: 0.1977 - accuracy: 0.8945 - precision: 0.6382 - recall: 0.8395 - auc: 0.9671 - val_loss: 0.2626 - val_accuracy: 0.8707 - val_precision: 0.4880 - val_recall: 0.4485 - val_auc: 0.8522\n",
      "Epoch 20/80\n",
      "49/49 [==============================] - 5s 94ms/step - loss: 0.1860 - accuracy: 0.8842 - precision: 0.6524 - recall: 0.8724 - auc: 0.9723 - val_loss: 0.3369 - val_accuracy: 0.8740 - val_precision: 0.4254 - val_recall: 0.4191 - val_auc: 0.8162\n",
      "Epoch 21/80\n",
      "49/49 [==============================] - 5s 97ms/step - loss: 0.1778 - accuracy: 0.9004 - precision: 0.6845 - recall: 0.8657 - auc: 0.9740 - val_loss: 0.2811 - val_accuracy: 0.9052 - val_precision: 0.5663 - val_recall: 0.3456 - val_auc: 0.8532\n",
      "Epoch 22/80\n",
      "49/49 [==============================] - 4s 87ms/step - loss: 0.1967 - accuracy: 0.8922 - precision: 0.6436 - recall: 0.8668 - auc: 0.9670 - val_loss: 0.2809 - val_accuracy: 0.8906 - val_precision: 0.4806 - val_recall: 0.4559 - val_auc: 0.8633\n",
      "Epoch 23/80\n",
      "49/49 [==============================] - 5s 94ms/step - loss: 0.1766 - accuracy: 0.8952 - precision: 0.6639 - recall: 0.8929 - auc: 0.9757 - val_loss: 0.2689 - val_accuracy: 0.8979 - val_precision: 0.5093 - val_recall: 0.4044 - val_auc: 0.8649\n",
      "Epoch 24/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.1861 - accuracy: 0.9037 - precision: 0.6536 - recall: 0.8586 - auc: 0.9722 - val_loss: 0.3033 - val_accuracy: 0.9005 - val_precision: 0.5059 - val_recall: 0.3162 - val_auc: 0.8295\n",
      "Epoch 25/80\n",
      "49/49 [==============================] - 4s 91ms/step - loss: 0.1873 - accuracy: 0.8997 - precision: 0.6484 - recall: 0.8579 - auc: 0.9685 - val_loss: 0.3403 - val_accuracy: 0.8939 - val_precision: 0.4242 - val_recall: 0.3088 - val_auc: 0.8326\n",
      "Epoch 26/80\n",
      "49/49 [==============================] - 4s 88ms/step - loss: 0.1956 - accuracy: 0.8851 - precision: 0.5959 - recall: 0.8719 - auc: 0.9699 - val_loss: 0.2966 - val_accuracy: 0.8866 - val_precision: 0.5268 - val_recall: 0.4338 - val_auc: 0.8321\n",
      "Epoch 27/80\n",
      "49/49 [==============================] - 5s 95ms/step - loss: 0.1554 - accuracy: 0.9070 - precision: 0.6802 - recall: 0.8900 - auc: 0.9807 - val_loss: 0.2970 - val_accuracy: 0.8919 - val_precision: 0.5146 - val_recall: 0.3897 - val_auc: 0.8410\n",
      "\n",
      "64 128 256\n",
      "Training model 4\n",
      "Epoch 1/80\n",
      "49/49 [==============================] - 9s 169ms/step - loss: 0.6985 - accuracy: 0.4287 - precision: 0.1495 - recall: 0.1772 - auc: 0.5682 - val_loss: 0.5196 - val_accuracy: 0.3123 - val_precision: 0.2310 - val_recall: 0.6912 - val_auc: 0.7896\n",
      "Epoch 2/80\n",
      "49/49 [==============================] - 8s 163ms/step - loss: 0.5524 - accuracy: 0.6324 - precision: 0.2824 - recall: 0.4352 - auc: 0.7673 - val_loss: 0.4795 - val_accuracy: 0.4344 - val_precision: 0.2475 - val_recall: 0.7426 - val_auc: 0.8452\n",
      "Epoch 3/80\n",
      "49/49 [==============================] - 8s 164ms/step - loss: 0.3817 - accuracy: 0.7254 - precision: 0.4101 - recall: 0.6534 - auc: 0.8892 - val_loss: 0.3424 - val_accuracy: 0.6777 - val_precision: 0.3022 - val_recall: 0.6176 - val_auc: 0.8472\n",
      "Epoch 4/80\n",
      "49/49 [==============================] - 12s 240ms/step - loss: 0.3051 - accuracy: 0.8056 - precision: 0.4841 - recall: 0.7192 - auc: 0.9325 - val_loss: 0.3566 - val_accuracy: 0.7520 - val_precision: 0.3056 - val_recall: 0.6471 - val_auc: 0.8563\n",
      "Epoch 5/80\n",
      "49/49 [==============================] - 14s 285ms/step - loss: 0.2421 - accuracy: 0.8448 - precision: 0.5613 - recall: 0.8136 - auc: 0.9547 - val_loss: 0.3197 - val_accuracy: 0.7911 - val_precision: 0.3795 - val_recall: 0.6250 - val_auc: 0.8695\n",
      "Epoch 6/80\n",
      "49/49 [==============================] - 14s 276ms/step - loss: 0.2004 - accuracy: 0.8699 - precision: 0.6063 - recall: 0.8381 - auc: 0.9682 - val_loss: 0.3277 - val_accuracy: 0.8515 - val_precision: 0.4194 - val_recall: 0.5735 - val_auc: 0.8784\n",
      "Epoch 7/80\n",
      "49/49 [==============================] - 13s 268ms/step - loss: 0.1727 - accuracy: 0.8951 - precision: 0.6330 - recall: 0.8828 - auc: 0.9764 - val_loss: 0.4117 - val_accuracy: 0.8641 - val_precision: 0.3879 - val_recall: 0.4706 - val_auc: 0.8250\n",
      "Epoch 8/80\n",
      "49/49 [==============================] - 13s 267ms/step - loss: 0.1577 - accuracy: 0.9057 - precision: 0.6679 - recall: 0.8978 - auc: 0.9804 - val_loss: 0.4107 - val_accuracy: 0.8289 - val_precision: 0.3664 - val_recall: 0.6250 - val_auc: 0.8375\n",
      "Epoch 9/80\n",
      "49/49 [==============================] - 13s 273ms/step - loss: 0.1572 - accuracy: 0.9158 - precision: 0.6803 - recall: 0.9008 - auc: 0.9784 - val_loss: 0.3937 - val_accuracy: 0.8574 - val_precision: 0.3908 - val_recall: 0.5000 - val_auc: 0.8465\n",
      "Epoch 10/80\n",
      "49/49 [==============================] - 13s 272ms/step - loss: 0.1136 - accuracy: 0.9272 - precision: 0.7306 - recall: 0.9247 - auc: 0.9889 - val_loss: 0.4206 - val_accuracy: 0.8607 - val_precision: 0.4140 - val_recall: 0.4779 - val_auc: 0.7937\n",
      "Epoch 11/80\n",
      "49/49 [==============================] - 13s 268ms/step - loss: 0.0973 - accuracy: 0.9313 - precision: 0.7183 - recall: 0.9422 - auc: 0.9914 - val_loss: 0.4735 - val_accuracy: 0.8641 - val_precision: 0.3944 - val_recall: 0.4118 - val_auc: 0.7621\n",
      "Epoch 12/80\n",
      "49/49 [==============================] - 13s 266ms/step - loss: 0.1019 - accuracy: 0.9442 - precision: 0.7485 - recall: 0.9342 - auc: 0.9911 - val_loss: 0.4680 - val_accuracy: 0.8707 - val_precision: 0.4130 - val_recall: 0.4191 - val_auc: 0.7855\n",
      "Epoch 13/80\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 0.0931 - accuracy: 0.9388 - precision: 0.7561 - recall: 0.9201 - auc: 0.9926 - val_loss: 0.4868 - val_accuracy: 0.8793 - val_precision: 0.4452 - val_recall: 0.4779 - val_auc: 0.7840\n",
      "Epoch 14/80\n",
      "49/49 [==============================] - 9s 187ms/step - loss: 0.0945 - accuracy: 0.9475 - precision: 0.7873 - recall: 0.9603 - auc: 0.9927 - val_loss: 0.5272 - val_accuracy: 0.8614 - val_precision: 0.4012 - val_recall: 0.4779 - val_auc: 0.7730\n",
      "Epoch 15/80\n",
      "49/49 [==============================] - 9s 183ms/step - loss: 0.0835 - accuracy: 0.9522 - precision: 0.7804 - recall: 0.9548 - auc: 0.9911 - val_loss: 0.5368 - val_accuracy: 0.8680 - val_precision: 0.4069 - val_recall: 0.4338 - val_auc: 0.7675\n",
      "Epoch 16/80\n",
      "49/49 [==============================] - 8s 159ms/step - loss: 0.0543 - accuracy: 0.9627 - precision: 0.8250 - recall: 0.9776 - auc: 0.9977 - val_loss: 0.5390 - val_accuracy: 0.8859 - val_precision: 0.4552 - val_recall: 0.4485 - val_auc: 0.7619\n",
      "Epoch 17/80\n",
      "49/49 [==============================] - 8s 158ms/step - loss: 0.1024 - accuracy: 0.9495 - precision: 0.7718 - recall: 0.9161 - auc: 0.9903 - val_loss: 0.5131 - val_accuracy: 0.8687 - val_precision: 0.3935 - val_recall: 0.4485 - val_auc: 0.7758\n",
      "Epoch 18/80\n",
      "49/49 [==============================] - 8s 161ms/step - loss: 0.0756 - accuracy: 0.9463 - precision: 0.7900 - recall: 0.9557 - auc: 0.9947 - val_loss: 0.5109 - val_accuracy: 0.8780 - val_precision: 0.4138 - val_recall: 0.4412 - val_auc: 0.7722\n",
      "Epoch 19/80\n",
      "49/49 [==============================] - 8s 162ms/step - loss: 0.0557 - accuracy: 0.9605 - precision: 0.8378 - recall: 0.9668 - auc: 0.9968 - val_loss: 0.5187 - val_accuracy: 0.8946 - val_precision: 0.4839 - val_recall: 0.4412 - val_auc: 0.7689\n",
      "Epoch 20/80\n",
      "49/49 [==============================] - 8s 163ms/step - loss: 0.0683 - accuracy: 0.9678 - precision: 0.8691 - recall: 0.9632 - auc: 0.9933 - val_loss: 0.5356 - val_accuracy: 0.8840 - val_precision: 0.4336 - val_recall: 0.4559 - val_auc: 0.7653\n",
      "Epoch 21/80\n",
      "49/49 [==============================] - 8s 164ms/step - loss: 0.0666 - accuracy: 0.9646 - precision: 0.8425 - recall: 0.9513 - auc: 0.9955 - val_loss: 0.5126 - val_accuracy: 0.8919 - val_precision: 0.4926 - val_recall: 0.4926 - val_auc: 0.7834\n",
      "Epoch 22/80\n",
      "49/49 [==============================] - 8s 161ms/step - loss: 0.0556 - accuracy: 0.9664 - precision: 0.8677 - recall: 0.9625 - auc: 0.9973 - val_loss: 0.5814 - val_accuracy: 0.8740 - val_precision: 0.4710 - val_recall: 0.4779 - val_auc: 0.7625\n",
      "Epoch 23/80\n",
      "49/49 [==============================] - 8s 167ms/step - loss: 0.0378 - accuracy: 0.9741 - precision: 0.8776 - recall: 0.9937 - auc: 0.9982 - val_loss: 0.6321 - val_accuracy: 0.8866 - val_precision: 0.4328 - val_recall: 0.4265 - val_auc: 0.7451\n",
      "Epoch 24/80\n",
      "49/49 [==============================] - 9s 174ms/step - loss: 0.0581 - accuracy: 0.9685 - precision: 0.8458 - recall: 0.9638 - auc: 0.9969 - val_loss: 0.5133 - val_accuracy: 0.8859 - val_precision: 0.4800 - val_recall: 0.4412 - val_auc: 0.7799\n",
      "Epoch 25/80\n",
      "49/49 [==============================] - 8s 174ms/step - loss: 0.0562 - accuracy: 0.9703 - precision: 0.8634 - recall: 0.9678 - auc: 0.9973 - val_loss: 0.6000 - val_accuracy: 0.8859 - val_precision: 0.4286 - val_recall: 0.4632 - val_auc: 0.7631\n",
      "Epoch 26/80\n",
      "49/49 [==============================] - 8s 163ms/step - loss: 0.0476 - accuracy: 0.9696 - precision: 0.8778 - recall: 0.9721 - auc: 0.9976 - val_loss: 0.5489 - val_accuracy: 0.8853 - val_precision: 0.4370 - val_recall: 0.4338 - val_auc: 0.7797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "M = 5\n",
    "models = [None] * M\n",
    "for m in range(M):\n",
    "    X, y, w = get_bootstrap_sample(X_train, y_train, w_train)\n",
    "    bias = calculate_bias(y)\n",
    "    r = np.random.randint(5)\n",
    "    models[m] = build_model(bias, r)\n",
    "    sgd = tf.keras.optimizers.SGD(lr=0.05, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "    models[m].compile(loss='binary_crossentropy', optimizer=sgd, metrics=get_metrics())\n",
    "    print(f'Training model {m}')\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=20, mode='max', restore_best_weights=True)\n",
    "    models[m].fit(\n",
    "      X, \n",
    "      y, \n",
    "      batch_size=128,\n",
    "      epochs=80, \n",
    "      shuffle=True,\n",
    "      verbose=1,\n",
    "      sample_weight=w,\n",
    "      validation_data=(X_val, y_val),\n",
    "      callbacks=[early_stopping]\n",
    "    )\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = np.zeros((M, X_test.shape[0]))\n",
    "for m in range(M):\n",
    "    m_pred = models[m].predict(X_test, batch_size=1)\n",
    "    votes[m] = m_pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = votes.sum(axis=0)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 8ms/step - loss: 0.3431 - accuracy: 0.8118 - precision: 0.2979 - recall: 0.4746 - auc: 0.8247\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2959 - accuracy: 0.8395 - precision: 0.3973 - recall: 0.5028 - auc: 0.8231\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.2919 - accuracy: 0.8364 - precision: 0.3744 - recall: 0.4633 - auc: 0.8206\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2339 - accuracy: 0.8768 - precision: 0.4831 - recall: 0.3220 - auc: 0.8443\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.3390 - accuracy: 0.8441 - precision: 0.3850 - recall: 0.4915 - auc: 0.8076\n"
     ]
    }
   ],
   "source": [
    "for m in range(M):\n",
    "    models[m].evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_2 = models[4].predict(X_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95      2023\n",
      "         1.0       0.47      0.45      0.46       177\n",
      "\n",
      "    accuracy                           0.91      2200\n",
      "   macro avg       0.71      0.70      0.71      2200\n",
      "weighted avg       0.91      0.91      0.91      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [1 if (p > 0.5) else 0 for p in preds]\n",
    "y_pred = np.asarray(y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score:  0.6016844746407315\n",
      "Precision:  0.5984541847041847\n",
      "Recall:  0.6291569833675096\n"
     ]
    }
   ],
   "source": [
    "f_score, precision, recall = evaluate(harmonix_beats, preds_2, ids_test, True)\n",
    "\n",
    "print(\"F-score: \", f_score)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for m in range(M):\n",
    "    models[m].save(os.path.join(ROOT, 'models', f'model_{m}.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(os.path.join(ROOT, 'data', '06_Results', 'harmonix_voting.npz'), preds=preds, ids=ids_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
