(window.webpackJsonp=window.webpackJsonp||[]).push([[10],{143:function(e,t,n){"use strict";n.d(t,"a",(function(){return m})),n.d(t,"b",(function(){return f}));var r=n(0),a=n.n(r);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=a.a.createContext({}),u=function(e){var t=a.a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},m=function(e){var t=u(e.components);return a.a.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.a.createElement(a.a.Fragment,{},t)}},d=a.a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,o=e.parentName,l=c(e,["components","mdxType","originalType","parentName"]),m=u(n),d=r,f=m["".concat(o,".").concat(d)]||m[d]||p[d]||i;return n?a.a.createElement(f,s(s({ref:t},l),{},{components:n})):a.a.createElement(f,s({ref:t},l))}));function f(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=d;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var l=2;l<i;l++)o[l]=n[l];return a.a.createElement.apply(null,o)}return a.a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},76:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return o})),n.d(t,"metadata",(function(){return s})),n.d(t,"toc",(function(){return c})),n.d(t,"default",(function(){return u}));var r=n(3),a=n(7),i=(n(0),n(143)),o={id:"dsp_201",title:"Digital Signal Processing 201",sidebar_label:"DSP 201",slug:"/dsp_201"},s={unversionedId:"dsp_201",id:"version-final-report/dsp_201",isDocsHomePage:!1,title:"Digital Signal Processing 201",description:"This section will expand on the meaning of the concepts of various image representations of audio and how they can be leveraged to capture the long-term dependencies in the audio.",source:"@site/versioned_docs/version-final-report/dsp_201.md",slug:"/dsp_201",permalink:"/docs/dsp_201",editUrl:"https://github.com/kingsleyzissou/nnssa/edit/master/website/versioned_docs/version-final-report/dsp_201.md",version:"final-report",sidebar_label:"DSP 201",sidebar:"version-final-report/someSidebar",previous:{title:"Artificial Intelligence",permalink:"/docs/ai"},next:{title:"Metrics",permalink:"/docs/metrics"}},c=[{value:"Time-domain",id:"time-domain",children:[]},{value:"Frequency-domain",id:"frequency-domain",children:[]},{value:"Spectrograms",id:"spectrograms",children:[]},{value:"Mel Spectrograms",id:"mel-spectrograms",children:[]},{value:"Short-time Fourier Transform (STFT)",id:"short-time-fourier-transform-stft",children:[]}],l={toc:c};function u(e){var t=e.components,n=Object(a.a)(e,["components"]);return Object(i.b)("wrapper",Object(r.a)({},l,n,{components:t,mdxType:"MDXLayout"}),Object(i.b)("p",null,"This section will expand on the meaning of the concepts of various image representations of audio and how they can be leveraged to capture the long-term dependencies in the audio."),Object(i.b)("h2",{id:"time-domain"},"Time-domain"),Object(i.b)("p",null,Object(i.b)("img",Object(r.a)({parentName:"p"},{src:"https://github.com/kingsleyzissou/nnssa/raw/main/img/kick_wavplot.png",alt:null}))),Object(i.b)("p",null,Object(i.b)("em",{parentName:"p"},"An audio waveform of a kick drum hit")),Object(i.b)("p",null,"A time-domain representation of an audio signal displays the amplitude of a wave signal over time. Each additional frequency adds constructive and destructive wave interference. Therefore, an audio file with multiple frequencies for the same period of time will result in a complex wave form. From figures 7 and 8, it is not immediately clear what the fundamental frequency of each note is."),Object(i.b)("p",null,Object(i.b)("img",Object(r.a)({parentName:"p"},{src:"https://github.com/kingsleyzissou/nnssa/raw/main/img/composite.png",alt:null}))),Object(i.b)("p",null,Object(i.b)("em",{parentName:"p"},"Shows how 3 perfect sine waves with different frequencies can make up a complex sine wave")),Object(i.b)("h2",{id:"frequency-domain"},"Frequency-domain"),Object(i.b)("p",null,Object(i.b)("img",Object(r.a)({parentName:"p"},{src:"https://github.com/kingsleyzissou/nnssa/raw/main/img/10hz_sine.png",alt:"Sine wave",title:"Simple sine wave"}))),Object(i.b)("p",null,"The sound frequency is the number of oscillations per second of a sound wave and is measured in Hertz (Hz), this is often referred to as pitch. The lower the frequency, the lower the pitch of the sound is perceived."),Object(i.b)("p",null,"##\xa0Time-Frequency Domain"),Object(i.b)("p",null,Object(i.b)("img",Object(r.a)({parentName:"p"},{src:"https://github.com/kingsleyzissou/nnssa/raw/main/img/kick_spec.png",alt:null}))),Object(i.b)("p",null,Object(i.b)("em",{parentName:"p"},"A spectrogram of a kick drum hit. The intensity of each frequency is indicated by the colour. In this case, we can see the fundamental frequency for the kick drum is quite low")),Object(i.b)("p",null,"The time-frequency domain, in contrast to the time-domain, is a representation of the variation of an audio signal over time, rather than an average of the frequency over time (Kehtarnavaz, 2008)."),Object(i.b)("h2",{id:"spectrograms"},"Spectrograms"),Object(i.b)("p",null,Object(i.b)("img",Object(r.a)({parentName:"p"},{src:"https://github.com/kingsleyzissou/nnssa/raw/main/img/kick_spec.png",alt:null}))),Object(i.b)("p",null,Object(i.b)("em",{parentName:"p"},"A spectrogram of a kick drum hit. The intensity of each frequency is indicated by the colour. In this case, we can see the fundamental frequency for the kick drum is quite low")),Object(i.b)("p",null,"Spectrograms are a time-frequency domain representation of a digital audio signal. Frequencies are depicted linearly on the y-axis and time is represented on the x-axis and the amplitude of each frequency is represented by the intensity of the colour, giving us information of the frequency over time. Figure 10 gives a clear visual representation of this."),Object(i.b)("h2",{id:"mel-spectrograms"},"Mel Spectrograms"),Object(i.b)("p",null,Object(i.b)("img",Object(r.a)({parentName:"p"},{src:"https://github.com/kingsleyzissou/nnssa/raw/main/img/kick_melspec.png",alt:null}))),Object(i.b)("p",null,Object(i.b)("em",{parentName:"p"},"a log mel-spectrogram. The heatmap shows quite clearly that the fundamental frequency is low. Along the Y axis, we can see that the highest frequency marker is 8192 Hz compared to 10000 Hz from the regular spectrogram")),Object(i.b)("p",null,"Mel-spectrograms use the same fundamental concept as regular spectrograms, but use the Mel scale for the y-axis of the graph. Mel spectrograms excel in the areas of audio classification, automatic mood recognition, music genre classification and instrument classification (The Sound of AI, 2020a). Mel spectrograms make use of the STFT and therefore give a time-frequency domain representation of a song."),Object(i.b)("p",null,"##\xa0Fourier Transform"),Object(i.b)("p",null,Object(i.b)("img",Object(r.a)({parentName:"p"},{src:"https://miro.medium.com/max/942/1*uL4gqMutokf5r-M8P7bG7w.png",alt:null}))),Object(i.b)("p",null,Object(i.b)("em",{parentName:"p"},"A visual representation of waveforms being split by their frequency and converted using the Fourier transform (Dubey, 2018)")),Object(i.b)("p",null,"Taking an audio signal representation from the time-domain to the frequency-domain is not a trivial task. It requires a complex mathematical algorithm known as the Fourier transform to achieve this (Mu \u0308ller, 2016). Since digital audio signals are a discrete representation of a continuous analogue signal, the underlying transform that will be used is the Discrete Fourier Transform (Chaudhary, 2020). Due to computational complexity of the Discrete Fourier transform, a slightly modified ver- sion, known as the Fast Fourier transform (FFT), is more frequently used used (Dubey, 2018)."),Object(i.b)("h2",{id:"short-time-fourier-transform-stft"},"Short-time Fourier Transform (STFT)"),Object(i.b)("p",null,"In order to calculate an SFTF, an audio signal is split up into equal size, overlapping windows and a Fast Fourier transform is then applied to each window. Rather than reporting the frequency\naveraged over time, the STFT reports the frequency variation over time, giving us a time-frequency domain representation of a signal (Kehtarnavaz, 2008). The STFT is used the underlying transform used to generate spectrograms and mel spectrograms."))}u.isMDXComponent=!0}}]);